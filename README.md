|           목차               |            제목               |
|-----------------------------|------------------------------|
|           1                 |     [리눅스](#리눅스)           |
|           2                 |     [CS 지식](#CS지식)         |
|           3                 |     [Nginx](#Nginx)         |
|           4                 |     [Micro Service Architecture](#MSA)         |
|           5                 |     [Elasticsearch](#Elasticsearch)         |
|           6                 |     [Python](#Python)         |


# 리눅스
* 사용자는 리눅스 커널과 통신하기 위해 리눅스 쉘사용. 정확히는 커널과 운영체제를 이어주는 것
* 터미널은 하나의 프로세스이고 명령어 실행은 해당 터미널의 정보를 기준으로 백그라운드에 자식프로세스가 fork되어 명령어 실행된다. 즉 터미널에서 ‘ls’라는 명령어를 입력하면 자식프로세스 1개가 fork되어 백그라운드에서 부모프로세스의 정보를 기준으로 해당 명령어 즉, stdin을 통해 정보를 입력받고 stdout을 통해 ls명령어를 호출한 터미널로 정보를 반환하는 식으로 동작

### 커널
운영 체제(OS)의 주요 구성 요소이며 컴퓨터 하드웨어와 프로세스를 잇는 핵심 인터페이스입니다. 그리고 두 가지 관리 리소스 사이에서 최대한 효과적으로 통신한다.

커널의 기능
메모리 관리: 메모리가 어디에서 무엇을 저장하는 데 얼마나 사용되는지를 추적합니다.
프로세스 관리: 어느 프로세스가 중앙 처리 장치(CPU)를 언제 얼마나 오랫동안 사용할지를 결정합니다.
장치 드라이버: 하드웨어와 프로세스 사이에서 중재자/인터프리터의 역할을 수행합니다.
시스템 호출 및 보안: 프로세스의 서비스 요청을 수신합니다.

### fork란:
 원래 실행되던 프로세스의 복사본을 만드는 함수이다. 최초의 프로세스를 부모 프로세스라고 하고 fork되어서 만들어진 프로세스를 자식 프로세스라고 한다. 자식프로세스는 fork를 실행한 부모 프로세스의 기존 구조를 그대로 가져온다. 그리고 두 개의 프로세스는 동시에 실행된다. 하지만 fork로 새로 만들어진 프로세스는 자신만의 process id를 가지게 된다. 다시말해 fork는 새로운 프로세스를 위한 메모리를 할당한 후 fork를 호출한 프로세스를 새로운 공간으로 전부 복사한다. 그리고 나서 원래 프로세스는 원래 프로세스대로 실행되고 fork를 이용해서 생성된 프로세스도 그 나름대로 fork시스템 콜이 수행된 라인의 다음 라인부터 실행이 된다. fork함수는 멀티프로세싱을 위한 기본적인 함수이다. fork가 성공하면 부모 프로세스에게는 자식의 process id를 반환하며 자식 프로세스에게는 0을 반환 한다. 만약 실패한다면 부모 프로세스에게 -1을 반환하며 자식 프로세스는 생성되지 않는다.

### 파일 디스크립터:
 파일이나 기타 입력/출력 리소스에 액세스하는 데 사용되는 추상표현이다. 시스템으로 부터 할당받은 파일이나 소켓을 대표하는 정수다.
 유닉스에서는 기본적으로 입력을 터미널 키보드와 연결시키고 출력을 터미널 디스플레이와 연결시킨다. 유닉스는 키보드와 모니터를 포함항여 컴퓨터의 모든 것을 파일로 모델링하는 것으로 유명하다. 따라서 디스플레이에 데이터를 쓰는 것은 스크린 위에 데이터 디스플레이를 담당하는 어떤 파일에 데이터를 쓰는 것이다. 비슷하게 키보드에서 데이터를 읽어오는 것은 키보드를 나타내는 어떤 파일에서 데이터를 읽어오는 것이다. 데이터는 바이트를 한 곳에서 다른 곳으로 전송하는 스트림을 통해 흐른다.
  
 3가지의 디폴트 입출력 스트림
 stdin, stdout, stderr 이 스트림틀은 각자 특정한 파일 디스크립터를 갖고 있다. 각 파일 디스크립터는 어떤 정수 값인데 그것은 어떤 하나의 오픈파일과 연결되어 있다.
 그리고 프로세스들은 파일 디스크립터를 이용해 데이터를 처리한다. 그 3가지의 기본 스트림들은 다음과 같은 파일 디스크립터 숫자를 갖고 있다. stdin=0, stdout=1, stderr=2. 이 파일 디스크립터들은 어떤 하나의 파일 디스크립터 테이블에 저장되어 있다. 그리고 각 프로세스는 자신만의 파일 디스크립터 테이블을 갖고 있으며, 프로세스가 생성될 때 기본적으로 0,1 그리고 2가 해당하는 스트림들에게 각각 맵핑된다. 
 각 스트림은 자신에게 맵핑된 파일 디스크립터에겍 보낸 데이터가 어디로 가는지 또는 그 파일 디스크립터로부터 받은 데이터가 어디로부터 오는지 알 지 못한다. 스트림은 자신의 파일 디스크립터를 통햏 데이터를 처리할 뿐 실제 데이터 리소스를 직접 처리하는 것이 아니다. 

 따라서 프로세스는 파일 디스크립터들만 처리하면 되고 실제 그 파일을 처리하지는 않는다. 대신 커널이 안전하게 그 파일을 관리한다. 그리고 프로세스는 0,1,2 이외에도 다른 파일 디스크립터를 사용하게 되는데, 새로운 파일 디스크립터가 할당될 때는 가장 낮은 숫자의 아직 사용되지 않은 파일 디스크립터가 사용된다. 따라서 0,1,2가 디폴트로 설정된 이후에 다음으로 사용될 파일 디스크립터는 3이다.

### 데이터 흐름:
터미널에서 어떤 명령을 실행시킬 때는 입력과 출력이 적절하게 처리되어야 한다. 각 명령은 어떤 데이터를 입력으로 받아야 할지 그리고 어떤 데이터를 출력으로 내보내야 할지를 알아야 한다. 키보드는 명령을 수행하는 프로그램에게 데이터를 전달하고(명령어 입장에서는 stdin을 통해 입력을 받는다) 그 프로그램은 stdout을 통해 터미널에게 데이터를 출력한다. 각 입력과 출력에 대응되는 파일 옆에는 파일 디스크립터 번호가(0,1) 있다. 일반적으로 데이터가 어떤 곳으로 흘러들어가는 것을 입력이라고 하며, 데이터가 어떤 곳으로 부터 흘러나가는 것을 출력이라고 한다.

터미널로 데이터를 출력할 수 있는 스트림은 기본적으로 2가지(stdout, stderr)
stderr스트림은 어떤 명령을 실행시킬 때 오류가 있을 경우 사용된다. 예를 들어 존재하지 않는 디렉토리의 컨텐츠를 리스트하려고 하면 에러가 발생하고 에러를 출력하기 위해 사용된 스트림은 사실 stderr이며, stdout이 아니다. 따라서 stderr또한 기본적으로 터미널에 출력하기 때문에 오류 메세지를 터미널에서 볼 수 있다.
```
test-Jaeho:~ Jaeho$ ls testdirect
ls: testdirect: No such file or directory
```
몇몇 명령들은 입력 출력 모두 사용한다. 둘 중 하나만 사용하거나 아예 사용하지 않는 것도 있다. 우선 입력의 진정한 의미에 대해서 알아보자 쉘 입장에서 봤을 때는 키보드로 입력되는 모든 것이 입력인 것이다. 하지만 우리는 좀 더 구체적으로 명령을 처리하는 프로세스가 파일들로부터 데이터를 주고받기 위해서 명령들에게 필요한 입력과 출력에 대해 알아보자. 명령의 옵션인자들은 커맨드 라인으로부터 읽히는데 비해서 실제 입력은 파일 디스크립터와 연결된 오픈파일로 부터 읽힌다. 따라서 입력은 stdin을 이용해 전달된 데이터 그리고 그 입력이 키보드를 통해서 입력되었는지, I/O 리다이렉션을 통해 리다이렉트되었는지, 또는 명령에게 파일인자로 전달되었는지 상관없이 어떤 파일인자가 명령에 전달되었을 때 프로세스가 실질적으로 그 파일의 컨텐츠를 읽거나 변경할 경우 그것을 입력으로 생각할 것이다. 하지만 단순히 그 파일을 참조하는 경우에는 입력으로 간주 하지 않는다. 

입력은 없지만 출력은 있는 명령의 한 예로 ls명령을 생각할 수 있으며 익것은 현재 디렉토리에 있는 모든 파일과 디렉토리를 나열한다. 만약 어떤 명령이 stdin으로 부터 입력을 받지 않는다면 그 명령으로 전달되는 데이터는 그 명령을 실행하는 프로그램에 의해 무시될 것이다. 왜냐하면 그 명령은 입력 데이터를 처리하도록 만들어지지 않았기 때문이다. 예를 들어 < wrods.txt ls를 입력하면 이것은 현재 디렉토리 안의 모든 파일과 디렉토리를 출력하고 stdin으로 리다이렉트된 입력 데이터는 무시할 것이다.

입력은 없지만 출력은 없는 명령의 한 예로 mv 명령을 생각할 수 있으며 이것은 파일을 이동시키거나 이름을 바꾸는데 사용된다. 내가 그 명령에게 이동시키거나 이름을 바꾸려고 하는 파일 또는 디렉토리의 이름 정확히 전달하면 stdout 또는 stderr 통해 출력 데이터는 없다. 전달되는 파일의 컨텐츠가 읽히거나 또는 사용되는 것이 아니기 때문에 전달된 파일은 입력이 아니다.

입력과 출력을 모두 사용하는 명령에 대한 예제로 sort명령이 있다. 만약 파일 인자와 입력 리다이렉션이 둘 다 없을 경우 터미널은 사용자가 정렬할 스트링을 입력할 때까지 대기한다. 그리고 사용자가 Ctrl-D를 입력하면(sort프로세스의 stdin과 키보드를 연결하는 커뮤니케이션채널의 쓰기 엔드(write end)종료) 그 sort명령을 실행하는 프로세스는 필요한 스트링이 전부 입력되었다고 생각할 것이다. 
```
test-Jaeho:~ Jaeho$ sort
bear
cobra
abrams
zero
abrams
bear
cobra
zero
```
그러므로 그 입력된 스트링들은 stdin을 통해 명령을 실행하는 프로세스에게 전달되고 그 프로세스에 의해 정렬된 후 stdout을 통해 터미널에게 출력된다. sort명령은 또한 사용자에게 직접 스트링을 받지 않고 파일 이름을 인자로 받아 그 파일 안의 스트링을 입력으로 사용할 수 있다. 이것은 아까 말한 입력의 정의를 만족하는데 왜냐하면 그것은 파일이면서 sort -r과 같은 옵션인자가 아니기 때문에다. 게다가 sort명령은 리다이렉션을 통해서도 입력을 전달받을 수 있다. 

### 버퍼:
입출력 전송 속도차이에 대한 성능을 보완하기 위해 사용. 입력속도에 비해 출력 속도가 느린경우 데이터를 임시 저장하는 공간을 말하며 임시저장장치라고도 한다.
버퍼를 사용하면 운영체제의 API 호출 횟수를 줄여 입출력 성능을 개선하게 된다. 스트림과 버퍼는 항상묶여다니는게 좋을것 같지만 빠른 반응이 요구되는 게임과 프로그램에서는 버퍼를 사용할 경우반응이 느릴수 있다.

### 리눅스 파이프:
파이프는 데이터가 한 프로세스에서 다른 프로세스로 전달되도록 하는데(일방향의 데이터 흐름을 통해서), 그로인해 프로세스들의 명령들이 스트림에 의해 서로 연결된다. 이것은 여러 명령들이 함께 동작하여 더 큰 목적을 달성할 수 있도록 해준다. 
이러한 프로세스들의 체이닝은 파이프라인으로 표현될 수 있다. 한 파이프라인 안에 있는 명령들은 서로 파이프에 의해서 연결되며 파이프의 한 쪽 끝에서 다른 쪽 끝으로 데이터가 흐르면서 두 프로세스 사이에 데이터가 공유된다. 이 때 파이프라인 안에 있는 각 명령들은 각자 독립적인 프로세스 안에서 실행되며, 각자 독립적인 메모리 공간에서 실행된다. 그러므로 우리는 각 프로세스들이 서로 통신할 수 있는 방법이 필요하게 되는데, 바로 pipe() 시스템 호출이 그 방법을 제공한다. 
구현에 있어서 사실 파이프는 그저 버퍼된 스트림에 불과하며 그 스트림은 2개의 파일 디스크립터와 연결되어 있는데 첫 번째는 데이터를 읽기위한 것이고, 두 번째는 데이터에 쓰기 위한 것이다. 더욱 구체적으로, 파이프라인의 명령의 실행을 처리하는 코드를 살펴보면, 2개의 정수값을 저장하는 배열이 생성되고, pipe()호출은 그 배열에 사용 가능한 2개의 파일 디스크립터 값을(일반적으로 사용가능한 가장 낮은 숫자의 2개의 파일 디스크립터를 사용한다)채운다. 
우리는 한 프로세스에서 시작되는 데이터 스트림을 독립된 공간에 들어있는 물이라고 생각할 수 있다. 그리고 그 물이 다음 프로세스의 공간으로 흐를 수 있는 유일한 방법은 각 공간을 파이프로 연결하는 것이다. 이러한 방식으로, 그 물(데이터)는 첫 번째 공간(프로세스)에서 파이프로 흘러들어가고, 파이프 안에 물이 가득차면, 다시 그 파이프에서 다음 공간(프로세스)으로 물(데이터)을 흘려보낸다.
(sort | grep ea) -> 기본적으로 sort명령은 사용자가 stdin을 통해서 입력을 전달할 때까지 기다린 다음 입력받은 스트링들은 알파벳 순서대로 정렬되고, 그 정렬된 결과가 stdout을 통해서 파이프로 전달된다. 이것은 stdout으로 하여금 출력된 데이터를 터미널 디스플레이가 아니라 파이프의 왼쪽 끝으로 입력하도록 만듦으로써 가능해진다. 
각 프로세스는 자신만의 파일 디스크립터 테이블을 갖는다는 것이다. 파이프라인의 각 명령은 각자 독립적인 프로세스 안에서 실행되기 때문에 각 명령은 자신만의 버전의 파일 디스크립터를 갖고 있으며, 자신만의 stdin, stdout, stderr를 갖고 있다. 이것이 의미하는 것은 위의 다이어그램에서 왼쪽 끝에 있는 1과는 다른 파일 디스크립터 테이블 안에 있는 것이고, 그것은 grep명령을 실행하는 프로세스에 속하는 것이다. 하지만 스트림들은 프로세스 바운더리를 건너 데이터를 전송하도록 설정되어 있기 때문에 데이터가 파이프라인을 타고 잘 전달된다면 결과적으로 데이터는 마지막 프로세스로 전달될 것이다.
다시 처음부터 살펴보면 sort명령은 정렬된 스트링 리스트를 출력(output)으로 갖게되고, 그 출력 데이터를 결과적으로 다음 프로세스(grep)에게 전달하기 위해서, 생성된 파이프에게 출력 데이터를 전달해야 한다. 데이터는 sort프로세스로부터 파이프로 전달되고 그것은 다시 파이프로부터 grep프로세스로 전달된다. 이제 pipe호출에 의해 전달된 파일 디스크립터에 대해 알아보자 파이프라인에서 명령들을 실행하는 코드 안에서, pipe호출은 파일 디스크립터 배열을 채우게 되고 따라서 파일 디스크립터 4에 쓰여진 데이터가 파일 디스크립터 3으로부터 읽히도록 만든다.  
배열 속에 들어가는 값들은 오직 프로세스에게만 중요하다. 하지만 각 파일 디스크립터의 용도는 데이터에게 있어 매우 중요하다. 그리고 각 파일 디스크립터의 용도는 배열안에서 몇 번째 인덱스에 위치하느냐에 따라서 결정된다. 그리고 여기에서 알아야 할 매우 중요한 개념이 있는데 다이어그램들은 데이터가 왼쪽에서 오른쪽으로 흐르는 모델이라는 것을 잘 생각해보자. 파일 디스크립터는 배열안에서 설정되어 4에 쓰여진 데이터가 3에서 읽히도록 된다. 하지만 왜 4가 왼쪽으로 가고 3이 오른쪽으로 갈까. 
여기서 핵심적인 내용은 바로 pipe호출에 의해 설정되는 읽기 쓰기 액션은 바로 파이를 사용하는 양쪽2개의 프로세스들의 관점에서 정의된다는 것이다. 따라서 pipe호출에 4를 writable end로 설정하면 그것은 첫 번째 명령(sort)의 프로세스가 출력(output)을 쓰기(write)하는 파이프의 입력(input)을 전달받는 파이프의 왼쪽 파일 디스크립터가 되는 것이다. 반대로 pipe()호출에 3을 readable end로 설정하면 그 것은 두 번째 명령(grep)의 프로세스가 입력(input)을 읽기(read)하는 파이프의 출력을 전달하는 파이프의 오른쪽 파일 디스크립터가 되는것이다.
따라서 데이터는 첫 번째 프로세스(sort)에서 파이프로 전달되고, 파이프는 모든 데이터가 전달될 때까지 기다렸다가 모든 데이터가 전달되면 파이프는 그 다음 프로세스(grep)로 그 데이터를 보낸다. 그리고 마지막으로 파이프로부터 데이터를 전달받은 grep명령을 실행하는 프로세스는 그 입력 데이터중에서 ‘ea’가 포함된 라인을 stdout으로 출력하여 터미널로 내보내게 된다. 

### iptables란:
iptables는 리눅스상에서 방화벽을 설정하는 도구로서 iptables는 커널상에서의 netfilter 패킷필터링 기능을 사용자 공간에서 제어하는 수준으로 사용가능

# CS지식

### stack/queue 차이: 
스택은 선형자료구조의 일종으로 나중에 들어간 원소가 먼저 나온다
큐는 선형자료구조의 일종으로 먼저들어간 원소가 먼저 나온다

### Array/Linked list 차이:
어레이는 논리적 저장 순서와 물리적 저장 순서가 일치해 인덱스로 해당 원소 O(1)로 접근가능한 자료구조
삭입 삭제 과정에서는 해당 원소에 접근하여 작업을 완료한 뒤 원소들을 shift 해줘야 하는 비용이 발생한다
링크드리스트는 자기 자신 다음에 어떤 원소인 기억하고 있다 이 부분만 바꿔주면 삽입 삭제를 O(1)에 해결
원하는 위치에 삽입하고 싶다면 첫번째 원소 부터 다 확인해봐야 한다 또한 원소를 삭제 삽입하기 위해서는 그 원소를 찾기 위해 O(n)의 시간이 추가적으로 발생

### Tree/heap 개념:
트리는 비선형자료구조이다 계층적 관계를 표현하는 자료 구조
힙은 우선순위 큐를 위해 고안된 완전이진트리 형태의 자료 구조이다 배열에 트리의 값들을 넣어줄 때  0번째는 건너뛰고 1번 인덱스 부터 루트 노드가 시작된다 힙의 구조를 계속 유지하기 위해서는 맨 마지막 노드를 루트 노드로 대체 시킨후 heapify O(logn)를 거처 heap구조를 유지한다
maxheap은 각 노드의 값이 해당 children노드 보다 크거나 같은 힙
minheap은 각 노드의 값이 해당 children노드 보다 작거나 같은 힙

### 최대 힙에서의 삭제:
힙의 루트를 삭제하고 가장 마지막 노드가 루트 노드로 올라오고 힙 연산반복

### Priority queue란:
우선순위가 높은 데이터가 먼저 나가는 형태의 자료구조이다

### 배열 한 개로 스택 세 개를 구현 해보기:
배열을 3등분해서 각 스택의 공간을 정적으로 할당 공간을 동적으로 사용하면 스택에 넣을 공간이 부족할 때 스택의 공간을 늘려주고 그 자리 원소들은 밀어준다. 노드로 구현한다면 정적으로 지정해 줄 필요없이 세 스택의 총 길이가 배열의 길이를 넘지 않도록만 해준다

## 트리란:
비선형 자료구조로 계층적 관계를 표현하는 자료구조

### Binary Tree:
루트 노드를 중심으로 두 개의 서브 트리로 나눠지는 트리 또한 나눠진 트리또한 Binary Tree이어야 한다

### Full binary, Complete Binary, Perfect Binary tree:
Full Binary: 모든 레벨이 꽉찬 이진 트리
Complete Binary: 위에서 아래로, 왼쪽에서 오른쪽으로 순서대로 채워진 이진트리
Perfect Binary: 모든 노드가 0개 또는 2개의 자식노드만 가진 이진트리

### BST:
이진 트리의 일종으로 특정 규칙으로 데이터를 저장, 탐색 연산은 평균O(log n) 
규칙: 노드에 저장된 키는 유일, 부모의 키가 왼쪽 자식 노드의 키보다 크고 오른쪽 자식 노드의 키보다 작다, 왼쪽과 오른쪽 서브트리도 이진탐색트리다
Worst Case: 저장 순서에 따라 계속 한 쪽으로만 노드가 추가되는 경우가 발생 이 경우 Rebalancing기법을 사용해 해결(Red Black Tree, AVL Tree, B(Balanced) Tree)

### B tree란:
노드에 많은 수의 정보를 갖고 최대 M개의 자식을 가질 수 있는 트리를 M차 B트리라고한다
노드는 최대 M개 부터 M/2개 까지 자식을 가질수 있다
각 노드 데이터에서 작은 것은 왼쪽, 높은 것은 오른쪽으로 나뉘어 분류 된다(항상 정렬된 상태)
노드에는 최대 M-1개 부터 M/2-1개 까지 자식을 가질 수 있다
노드의 키가 x개라면 자식의 수는 x+1이다
최소차수는 자식수의 하한값을 의미하며 최소차수가 t라면 M=2t-1을 만족
데이터 삽입/삭제가 발생하는 경우 해당 조건들을 만족시키기 위해 많은 연산이 필요
데이터 크기와 상관없이 균등한 검색 속도 제공

### 탐색시간이 제일 빠른 해시 테이블을 DB인데스로 사용할 수 없는 이유(B-Tree이유):
해시 함수를 통해 나온 해시 값을 이용하여 저장된 메모리 공간에 한 번에 접근을 하기 때문에 O(1)이라는 시간 복잡도를 가진다. 그러나 이는 온전히 단 하나의 데이터를 탐색하는 시간에만 O(1)이다. 우리는 DB에서 등호 뿐 아니라 부등호도 사용한다. 모든 값이 정렬되어 있지 않으므로 해시 테이블에서는 특정 기준보다 크거나 작은 값을 찾을 수 없다. 그러면 탐색이 O(logN)인 다른 자료구조나 알고리즘은 왜 사용하지 못하는 것일까? RedBalck Tree와 B-Tree를 비교 해보자 RBT의 특징은 각 노드는 하나의 값만 가진 상태로 좌,우 규칙에 맞춰 자식 노드의 개수 밸런스를 맞춘다. B-Tree는 노드 하나에 여러 데이터가 저장될 수 있다. 각 노드 내 데이터들은 항상 정렬된 상태이며, 데이터 와 데이터 사이의 범위를 이용하여 자식 노드를 가진다. 그러므로 자식 노드 개수는 (N+1)을 가진다. 위 두 개의 트리는 항상 좌,우 자식노드 개수의 밸런스를 유지함므로 최악의 경우에도 무조건 탐색 시간이 O(logN)을 가지게 된다.
그렇다면 왜 B-Tree를 사용하나? 그 이유는 하나의 노드가 가지는 데이터 개수때문이다. B-Tree는 하나의 노드에 여러 개의 데이터 요소를 저장한다. 같은 노드 공간의 데이터들끼리 실제 메모리 상에 차례대로 저장이 되어있어 참조 포인터 값으로 접근할 필요가 없다. 즉 같은 노드 상 데이터를 탐색할 때는 포인터 접근을 하는 것이 아니라 실제 메모리 디스크에서 바로 다음 인덱스로 접근을 하는 것이다.
(탐색 방식 순서)200이라는 값이 있는지 확인하기 위해, 100, 155, 226이 저장되어 있는 Root노드에 있는 데이터들을 탐색한다. 실제 메모리 디스크 상 순차적으로 저장되어 있는 데이터들을 빠르게 탐색한다. Root노드에 200이 없다. 200은 155와 226 사이의 값이므로 해당 범위에 존재하는 자식 노드를 가리키는 포인터가 존재 하는지 확인한다. 있으면 포인터를 통해 해당 자식 노드로 접근한다. 자식 노드 168은 200의 값을 가지고 있다. 실제 메모리 디스크 상 순차적으로 저장되어 있는 168, 200의 값을 빠르게 탐색한다. 찾으려 했던 200의 값을 찾아낸다.
RBT는 B-Tree와 다르게 각 노드마다 무조건 하나의 데이터만 가지게 되므로 모든 데이터를 접근할 때 무조건 참조 포인터로 접근 하게 된다. 따라서 B-Tree의 배열 형식의 접근과 RBT의 참조 포인터 접근의 시간 차이를 알아야 한다. 둘 다 시간 복잡도는 O(logN)이라는 것은 변함이 없다. 그러나 이러한 시간 복잡도는 알고리즘 처리에 대한 이론적인 시간 계산 방식일 뿐이다. 물리적, 절대적인 시간 개념으로는 배열 접근이 훨씬 빠를 수 밖에 없다. 참조 포인터로 메모리에 접근한다는 것은, 실제 메모리 상 순서대로 저장이 되었든 안 되었든 접근하려는 주소를 연산을 통해 직접 알아내어 데이터에 접근한다는 것이다. 주소를 알아내는데 CPU내부적으로 많은 연산을 수행하게 될 것이다. 이와 반대로 배열은 데이터들이 메모리 공간에 차례대로 저장이 되어 있으므로 접근할 주소를 바로 알 수 있다. 그래서 메모리 주소를 알아내는데 성능에 영향이 없다. 비록 B-Tree도 자식 노드를 접근할 땐 참조 포인터로 접근을 하지만, 하나의 노드가 가지는 데이터 개수가 많아 질 수록 포인터 개수는 확연히 줄어들고, 트리 내에서 다루는 데이터가 많아 질 수록 포인터 개수는 확연히 줄어들고, 트리 내에서 다루는 데이터가 많아 질 수록 이러한 차이는 더욱 커질 것이다. 비록 같은 O(logN)이지만 포인터 접근 수의 차이로 인해 B-Tree가 RBT보다 탐색 시간이 더 빠를 수 밖에 없다.
참조 포인터가 문제라면 그냥 참조 요소 자체가 없는 배열을 쓰면 되지 않나? 충분히 요소들이 정렬 상태를 유지하고 있다면 어쩌면 배열로도 무리가 없을 것 같아 보인다. 하지만 배열 역시 DB인덱스로 선택받지 못한 이유가 있다. 배열은 참조 포인터라는 개념이 없고 모든 데이터가 메모리 상 차례대로 저장되어 있어 접근이 매우 빠르다. 참조가 없으니 당연히 탐색 속도로만 본다면 B-Tree보다 훨씬 빠르다. 뿐만 아니라, 해시 테이블과 다르게 데이터들은 정렬 상태로 유지할 수 있으므로 부등호 연산에도 문제가 없다. 하지만 배열이 B-Tree보다 빠른 것은 탐색 뿐이다. 배열 내에서 데이터 저장, 삭제가 일어나는 순간 B-Tree보다 훨씬 비효율적인 성능이 발생하게 된다. 배열 중간에 3이라는 데이터를 삽입하게 되면, 삽입될 해당 자리를 찾은 뒤 3보다 큰 데이터들은 한 칸씩 뒤로 물러나게 된다. 이때 뒤로 한 칸씩 이동하는 과정에서 평균 복잡도가 O(N)이 걸리게 된다. 실제로는 CPU연산에 의해 맨 뒤에 데이터부터 시작해서 각 한 칸씩 뒤로 이동하는 작업을 모두 거치게 될 것이다. 그나마 새롭게 삽입되는 데이터가 가장 큰 데이터라서 바로 맨 뒤에 저장된다면 O(logN)이 걸리겠지만(탐색시간) 최악의 경우인 가장 작은 데이터라면 자리 탐색 시간인 O(logN)과 맨 앞에 새로운 데이터 삽입을 위해 모든 데이터를 한 칸씩 뒤로 이동하는 시간 O(N)이므로 총 O(N+logN)=O(N)이 걸리게 된다. 삭제의 경우에도 동일하다 삭제를 하면 삭제된 데이터의 공간을 메꾸기 위해 뒤에서 한 칸씩 앞으로 이동하는 과정인 O(N)이 걸리게 된다. 데이터 수정이 일어날때도 퀵 정렬, 병합 정렬 등 배열 자료구조에서 O(NlogN)시간으로 재정렬을 이루어야 한다는 점도 있다.

LinkedList가 DB인덱스로 선택받지 못한 이유:
배열이 탐색에서 빠른 이유가 무엇일까? 배열은 정렬이 된 상태와 되어있지 않은 상태가 있을 것이다. 정렬이 되어 있다면 이진탐색이 가능하며 이는 O(logN)의 시간을 보장한다. 이와 반대로 정렬이 되어 있지 않다면 Quick Sort, Merge Sort등 시간 복잡도가 average O(NlogN)인 알고리즘을 사용한다면 빠르게 정렬 시킬 수 있다. 하지만 이 알고리즘들은 배열의 총 길이를 미리 알아야 하고, Divided and Conquer가 일어날 때마다 해당되는 Index Number가 파악이 가능해야 하며, Index Number파악을 위해선 기존에 파악되어 있는 다른 Index Number 정보들을 이용해 또 다시 계산이 되어야 한다. LinkedList에 Index Number라는 개념이 있던가? 또한 각 요소에 Index Number정보들을 추가로 가지고 있다 해도, 그 Index Number로 해당 요소로 바로 접근을 할 수 있는가? 참조 포인터로만 이루어져 있는 LinkedList에서는 이 알고리즘을 적용할 수 없다. 탐색을 무조건 제일 앞 부분인 HEAD부터 시작해야하는 LinkedList로서는 DB-Index로 사용하기엔 매우 비효율 적인 자료구조가 되는 셈인 것이다.

결론 적으로 DB인덱스로 B-Tree가 가장 적합한 이유들은
1. 항상 정렬된 상태로 특정 값보다 크고 작은 부등호 연산에 문제가 없다.
2. 참조 포인터가 적어 방대한 데이터 양에도 빠른 메모리 접근이 가능하다.
3. 데이터 탐색뿐 아니라 저장, 수정, 삭제에도 항상 O(logN)의 시간 복잡도를 가진다.

### Red Black Tree:
1. 루트 노드의 색깔은 검정이다
2. 모든 External Node들은 검정이다
3. 빨강 노드의 자식은 검정이다 -> 빨간색 노드가 연속으로 나올 수 없다
4. 모든 리프노드에서 Black Depth는 같다 -> 리프노드에서 루트노드까지 가는 경로에서 만나는 블랙 노드의 개수는 같다
5. 삽입되는 노드의 색깔은 무조건 빨간색이다
 
Double Red를 해결하는 전략 2가지
w(사촌)가 검정일 땐 Restructuring 수행
w가 빨강일 땐 Recoloring 수행
  
Restructuring: 현재 insert된 노드(z)와 내 부모(v)와 부모의 부모(Grand Parent)를 가지고 Restructuring을 한다 
1. 나(z)와 내 부모(v) 내 부모의 부모(grand parent)를 오름차순으로 정렬
2. 무조건 가운데 있는 값을 부모로 만들고 나머지 둘을 자식으로 만든다
3. 올라간 가운데 있는 값을 검정으로 만들고 그 두 자식들을 빨강으로 만든다 
Restructuring은 다른 서브트리에 영향을 끼치지 않기 때문에 한번의 Restructuring이면 끝난다 또한 Restructuring자체의 시간복잡도는 O(1)에 끝나지만 어떤 노드를 insertion한 뒤에 일어나므로 총 수행시간은 O(log n)이다. 지금 현재 노드가 들어갈 위치를 찾아야 하기 때문이다.

Recoloring: 현재 삽입된 노드(z)와 부모와 그 형제(w)를 검정으로 하고 부모의 부모를 빨강으로 한다
부모의 부모가 root node가 아니었을 시 double red가 다시 발생 할 수 있다
각 노드에 색깔을 저장하는 공간을 추가하여 색깔을 기준으로 균형을 맞추는 트리

### 최대 힙이 그려져 있고 해당 최대 힙에 대해 삽입과 삭제가 어떻게 진행되는지 설명:
삽입되는 원소의 정확한 위치를 결정하기 위해, 트리의 새 노드에서 시작해서 루트쪽으로 올라가는 방법을 사용. 삽입되는 원소는 새 노드에 삽입이 되고나서, 최대 힙이 될 때까지 위로 올라가는 과정을 반복한다. 부모 노드보다 값이 클 경우 서로 교환하면서 위로 올라가는 과정을 반복 삭제할 때는 힙의 루트에서 삭제한다. 삭제하면 루트노드가 비워져 있는 상태이고, 가장 마지막 노드가 루트노드로 올라오게 된다. 새로 올라온 값이 제자리를 찾아갈 수 있도록 연산을 반복한다 

### 주어진 트리가 이진 탐색트리인지 확인:
주어진 트리를 중위순회하며 데이터를 임의의 다른 배열에 저장한다. 저장된 데이터들이 모두 오름차순으로 정렬되어있는지 확인한다. 저장된 데이터가 모두 오름차순으로 정렬되어있으면 True 아니면 False
위 방법은 트리에 저장된 노드의 개수만큼의 길이를 갖는 배열이 필요로 한다는 단점이 있다. 
하지만 주어진 트리에서 중위 순회를 하며 현재 값과 다음 값과의 비교를 통해 이진탐색트리의 조건을 만족하는지 확인가능

### 해시란:
데이터를 다루는 기법중 하나 
key값이 배열 인덱스로 변환되기 때문에 검색과 저장의 평균 시간 복잡도가 O(1)에 수렴

### 해시테이블이란:
Key,value쌍값으로 데이터를 저장하는 자료구조 중 하나
내부적으로 배열(버킷)을 사용하여 데이터를 저장하기 때문
해시 테이블의 각각의 key값에 해시 함수를 적용해 배열의 고유한 index를 생성(해쉬코드)하고 이 index를 활용해 값을 저장하거나 검색함

### 해시 충돌이란:
해시함수를 돌려 나온값이 동일하다면 동일한 key값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는것

### 해시 테이블에서 충돌 회피하는 2가지방법:
Open Address방식: 해시 충돌이 발생하면 다른 해시 버킷에 해당 자료를 삽입하는 방식
연속된 공간에 데이터를 저장하기 때문에 캐시 효율이 높다. 따라서 데이터의 개수가 충분히 적다면 Open Address방식이 성능이 좋다
Collision이 발생하면 데이터를 저장할 장소를 찾아 헤맨다. Worst Case경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아 올 수 있다
Linear probing: 순차적으로 탐색하며 비어있는 버킷을 찾을 때까지 계속 진행
Quadratic probing: 2차 함수를 사용해 탐색위치 찾는다
Double Hashing probing:  하나의 해쉬 함수에서 충돌이 발생하면 2차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 가지 방법에 비해 많은 연산량을 요구한다
  
Separate Chaining방식: 해시 충돌이 잘 발생하지 않도록 보조 해시 함수를 통해 조정
Linked List사용 방식: 각각의 버킷들은 연결리스트로 만들어 collision이 발생하면 해당 충돌 난 버킷의 list에 추가하는 방식. 삽입 삭제가 간단하다 하지만 연결 리스트 자체의 오버헤드가 부담 된다. 테이블의 확장을 open address방식에 비해 늦출수 있다
Red-Black-Tree사용 방식: 연결 리스트를 사용할 것인가와 트리를 사용할 것인가에 대한 기준은 하나의 해시 버킷에 할당된 key-value쌍의 개수이다. 데이터 개수가 적다면 연결리스트를 사용하는 것이 맞다. 트리는 기본적으로 메모리 사용량이 많기 때문이다. 

보조 해시 함수:
보조 해시 함수의 목적은 key의 해시 값을 변형하여 해시 충돌 가능성을 줄이는 것이다. Separate Chaining방식을 사용할 때 함께 사용되며 보조 해시 함수로 Worst Case에 가까워지는 경우를 줄일 수 있다.

해시 버킷 동적 확장(Resize);
해시 버킷의 개수가 적다면 메모리 사용을 줄일 수 있지만 해시 충돌로 인해 성능 상 손실이 발생. 그래서 해시맵은 key-value쌍 데이터 개수가 일정 개수 이상이 되면 해시 버킷의 개수를 두 배로 늘린다. 해시 버킷 쿠기를 두배로 확장하는 임계점은 로드팩터가 0.75가 될때이다

### 정렬 알고리즘:
Bubble Sort O(N^2) O(N^2) : 서로 인접한 두 원소를 검사하여 정렬하는 알고리즘, 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환한다 
Selection Sort O(N^2) O(N^2) : 첫 번째 자료를 두 번째 자료부터 마지막 자료까지 차례대로 비교하여 가장 작은 값을 찾아 첫 번째에 놓고, 두 번째 자료를 세 번째 자료부터 마지막 자료까지와 차례대로 비교하여 그 중 가장 작은 값을 찾아. 두 번째 위치에 놓는 과정을 반복
Insertion Sort O(N) O(N^2) : 손안의 카드를 정렬하는 방법과 유사, 자료 배열의 모든 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교 하여, 자신의 위치를 찾아 삽입함으로써 정렬 완성
Merge Sort O(NlogN) : 하나의 리스트를 두 개의 균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 정렬된 부분리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법
Heap Sort O(NlogN) : 최대 힙 트리나 최소 힙 트리를 구성해 정렬을 하는 방법
Quick Sort O(N^2) O(NlogN) : 하나의 리스트를 피봇(Pivot)을 기준으로 두 개의 비균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법
Count Sort O(N) : 요소 값들끼리 서로 비교하지 않고 정렬하는 알고리즘이다. 배열 내 최대 값 +1 만큼의 길이, 배열이 필요하기 때문에 메모리가 낭비될 수 있다.
Radix Sort O(N) : 낮은 자리수부터 비교하여 정렬해 간다는 것을 기본 개념으로 하는 정렬 알고리즘이다. 기수정렬은 비교 연산을 하지 않으며 정렬. 속도가 빠르지만 데이터 전체 크기에 기수 테이블의 크기만한 메모리가 더 필요하다

### 데이터베이스가 일반 파일 시스템과 차이: 
가장 큰 차이점은 무결성의 원칙이다. 파일 시스템은 논리적 파일 구조를 직접 물리적 파일 구조로 구현해야하고 사용자는 물리적 데이터 구조에 대해 잘 알고 있어야 하며 모든 응용 프로그램이 자기 자신의 파일을 가지고 있어 하나의 응용만을 존재한다는 특성이있다 따라서 데이터 공용을 할 수 없으며 데이터 종속성과 데이터 중복성의 문제점을 가지고 있다 데이터베이스는 파일의 이러한 문제점에서 출발한 것으로 사용자 측면에서 논리적구조(테이블,인덱스)의 데이터 집합을 지원하며 표준 언어를 이용하여 데이터 조작이 가능하다. 따라서 여러 응용 시스템들이 공용할 수 있도록 데이터를 통합 저장할 수 있다 데이터베이스는 실시간 접근성, 계속적인 변화, 동시 공용, 내용에 의한 참조의 특성을 가지고 있다

### 트랜잭션이란: 
데이터베이스의 상태(SELET, INSERT, DELETE, UPDATE)를 변화시키기 위해서 수행하는 작업의 단위

### ACID(Atomicity, Consistency, Isolation, Durability) 트랜잭션의 특징:
데이터베이스 트랜잭션이 안전하게 수행된다는 것을 보장하기 위한 성질(원자성, 일관성, 독립성, 지속성)
원자성은 트랜잭션이 데이터베이스에 모두 반영되던가 아니면 전혀 반영되지 않는것
일관성은 트랜잭션의 작업 처리 결과가 항상 일관성이 있어야 한다는것
독립성은 어떤 하나의 트랜잭션이라도, 다른 트랜잭션의 연산에 끼어들 수 없는 것
지속성은 트랜잭션이 성공적으로 완료됬을 경우 결과는 영구적으로 반영되어야 하는것

### BASE란:
ACID와 대조적으로 가용성과 성능을 중시하는 특성을 가진 분산 시스템의 특성

### BASE속성:
기본적인 가용성: 부분적인 고장은 있을 수 있으나, 나머지는 사용이 가능하다(주 서버가 다운되도 백업서버는 동작)
소프트 상태: 노드의 상태는 외부에서 전송된 정보를 통해 결정됨, 분산 노드 간 업데이트는 데이터가 노드에 도달한 시점에 갱신(최신 상태의 데이터로 덮어써진다)
결과적 일관성: 일시적으로 비일관적인 상태가 되어도 최적으로는 일관성이 있는 상태가 되는 성질(시스템 부하, 네트워크 속도 등의 외부 요인으로 인해 일관성이 일시적으로 깨질 수 있다)

### 트랜잭션의 격리수준:
트랜잭션 격리수준이란 동시에 여러 트랜잭션이 처리될 때, 트랜잭션끼리 얼마나 서로 고립되어 있는지를 나타내는 것이다. 데이터베이스는 ACID특징과 같이 트랜잭션이 독립적인 수행을 하도록 locking을 통해 트랜잭션이 DB를 다루는 동안 다른 트랜잭션이 관여하지 못하도록 막는 것이 필요하다.

### 데이터베이스의 이상현상:
갱신이상: 반복된 데이터 중에 일부를 갱신 할 시 데이터의 불일치가 발생
삽입이상: 불필요한 정보를 함께 저장하지 않고서는 어떤 정보를 저장하는 것이 불가능
삭제이상: 필요한 정보를 함께 삭제하지 않고서는 어떤 정보를 삭제하는 것이 불가능

### 정규화:
중복을 배제하여 삽입, 삭제, 갱신 이상의 발생을 방지

### 프로세스 메모리 할당 구조
<img width="518" alt="스크린샷 2022-02-19 오후 4 14 38" src="https://user-images.githubusercontent.com/42399580/154791020-1c4c7bd2-34f2-4851-87a7-228f2a213f06.png">
Code 영역: 프로그램 실행 코드를 위한 공간이다. 작성한 코드는 여기에 있다. 코드 영역은 읽기 전용이다.
Data 영역: 전역변수 등 고정된 데이터를 위해 할당된 공간이다.
Heap 영역: 동적할당 데이터를 위한 공간이다.
Stack영역: 함수에 필요한 데이터를 위한 공간이다. 지역변수가 이쪽에 저장된다.

 Code부터 Data까지는 불변 영역이지만 Heap부터 Stack은 가변적인 메모리 공간이다. Heap과 Stack은 사실 같은 메모리 공간을 사용한다. 하지만 같은 공간이라고 무작위로 저장이 되지 않고, Heap은 위에서부터 저장이되고 stack은 아래서부터 저장이 된다. Heap이 Stack영역을 침범 할수도 Stack이 Heap영역을 침범할 수도 있는데 Heap->Stack넘어설 때는 Heap Overflow, Stack->Heap을 넘어설 때는 Stack Overflow가 발생한다.

### 쓰레드 메모리할당 구조
<img width="518" alt="스크린샷 2022-02-19 오후 4 15 03" src="https://user-images.githubusercontent.com/42399580/154791038-d5742837-647a-4609-9a7f-e1a10c33679b.png">
Code 영역부터 Heap영역 까지는 모든 스레드가 공유하고 Stack영역만 사용한다.

### 프로세스/스레드차이
프로세스: 운영체제로부터 자원을 할당받는 작업의 단위. 디스크로부터 메모리에 적재되어 운영체제로부터 주소 공간, 파일 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 함. 
함수의 매개변수, 복귀 주소, 로컬 변수와 같은 임시 자료를 저장하는 프로세스 “스택”과 전역 변수들을 저장하는 데이터 섹션, 프로세스 실행 중에 동적으로 할당되는 메모리인 “힙”을 포함

스레드: 프로세스가 할당받은 자원을 이용하는 실행의 단위. 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 heap, data, code영역을 공유. 
하나의 프로세스를 다수의 실행 단위인 스레드로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 멀티스레딩이라고 함. 이 경우 각각의 스레드는 독집적인 작업을 수행해야 하기 때문에 각자의 스택과 PC레지스터 값을 가지고 있음

### 스택을 스레드마다 독립적으로 할당하는 이유
스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

### 싱글 스레드 장점
 자원 접근에 대한 동기화를 신경쓰지 않아도 된다: 여러개의 스레드가 공유된 자원을 사용할 경우, 각 스레드가 원하는 결과를 얻게 하려면 공용 자원에 대한 접근이 통제되어야 하며, 이 작업은 프로그래머에게 많은 노력을 요구하고 많은 비용을 발생시킨다. 단일 스레드 모델에서는 이러한 작업이 필요하지 않는다.
 작업전환 작업을 요구하지 않는다: 작업전환은 여러 개의 프로세스가 하나의 프로세서를 공요할 때 발생하는 작업으로 많은 비용을 필요로 한다

### 싱글 스레드 단점
여러개의 CPU를 활용하지 못한다: 프로세서를 최대한 활용하게 하려면 Cluster 모듈을 사용하거나 외부에서 여러 개의 프로그램 인스턴스를 실행시키는 방법을 사용해야 한다.
두 개의 작업을 하나의 스레드로 처리하는 경우와 두 개의 스레드로 처리하는 경우를 가정했을때 후자의 경우는 짧은 시간 동안 2개의 스레드가 번갈아 가면서 작업을 수행한다. 그래서 동시에 두 작업이 처리되는 것과 같이 느끼게 된다. 
하지만 오히려 두 개의 스레드로 작업한 시간이 싱글 스레드로 작업한 시간보다 더 걸릴 수 도 있는데, 그 이유는 스레드 간의 작업전환(Context Swithching)에 시간이 걸리기 때문이다.
따라서 단순히 CPU만을 사용하는 계산작업이라면 오히려 멀티 스레드보다 싱글 스레드로 프로그래밍하는 것이 더 효율적이다

### 멀티 스레드 장점
새로운 프로세스를 생성하는 것보다 기존 프로세스에서 스레드를 생성하는 것이 빠르다
프로세스의 자원과 상태를 공유하여 효율적으로 운영이 가능하다
프로세스의 작업 전환 보다 스레드의 작업 전환이 더 빠르다

### 멀티 스레드의 단점
* 하나의 스레드만 실행중일 때는 실행시간이 오히려 지연될 수 있다.
* 멀티 스레딩을 위해 운영체제의 지원이 필요하다
* 스레드 스케줄링을 신경써야 한다
* 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 그렇기 때문에 동기화 작업이 필요하다. 
* 동기화 작업을 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상을 줄여야 한다

### 동기화 기법
* 유저모드의 동기화: 커널모드로의 전환이 불필요 하기 때문에 성능상에 이점을 얻을 수 있다. 커널 모드 동기화에 비해 활용하는 방법도 단순하다
* 크리티컬 섹션 기반의 동기화(유저 모드 동기화): 방에 들어가기 전 열쇠로 문을 열고 들어가고 나와서는 열쇠를 걸어 놓는다. 핵심은 열쇠가 있어야  들어갈 수 있다.
* 인터락 함수 기반의 동기화(유저 모드 동기화): 위의 동기화 방식이 하나의 변수에 대한 접근 방식을 동깋화 하는 것이 목적이라면, 이러한 용도로 특화된 함수가 인터락 함수이다. 인터락 함수는 내부적으로 한 순간에 하나의 쓰레드에 의해서만 실행되도록 동기화 되어있다.
* 커널 모드 동기화: 커널 모드 동기화는 유저 모드 동기화에 비하면 느리다. 유저모드에서 커널 모드로, 커널 모드에서 유저 모드로 전환이 필요하기 때문 하지만 운영체제 커널 레벨에서 제공해주는 동기화 기법이기 때문에 유저 모드 동기화에서 제공해주지 못하는 기능을 제공받을 수 있다.
* 뮤텍스 기반의 동기화(커널 모드 동기화): 뮤텍스 기반 동기화 기법의 경우에는 열쇠에 비유할 수 있는 것이 뮤텍스 오브젝트이고 이는 크리티컬 섹션 오브젝트와 달리 HANDLE CreateMutex(1,2,3) 반환 타입이 HANDLE인 함수를 통해 만들어진다. 반환타입이 HANDLE인 것은 뮤텍스가 커널 오브젝트임을 말하는 것이다. 이렇게 뮤텍스가 커널 오브젝트인 점만 보더라도 뮤텍스는 커널 레벨 동기화 기법임을 알 수 있다. 이렇게 생성되는 뮤텍스는 크리티컬 섹션 오브젝트와 달리 초기화 함수의 호출이 필요없다(이미 함수를 호출하는과정에서 필요한 모든 초기화가 이루어지기 때문). 그런데 커널 오브젝트는 Signaled상태와 Non-Signaled상태를 지닌다. 보통 커널 오브젝트는 Non-Signaled상태에 놓여 있다가 뮤텍스가 누군가에 의해 획득이 가능할 때 Signaled상태가 된다. 한가지 더 기억할 사항은 WaitForSingleObject함수의 특성이다. 이 함수는 인자로 전달된 핸들의 커널 오브젝트가 Signaled상태가 되어서 반환하는 경우 해당 커널 오브젝트를 Non-Signaled상태로 변경한다. 쓰레드는 임계영역에 들어가기에 앞서 뮤텍스를 획득해야 한다. 따라서 뮤텍스 핸들을 인자로 전달하면서 WaitForSingleObject함수를 호출한다. 만약 뮤텍스가 획득 가능한 상태라면 Signaled상태에 있을 것이고 때문에 뮤텍스를 획득하면서 임계 영역에 진입하게 된다. WaitForSingleObject 함수는 커널 오브젝트가 Signaled상태가 되어 반환할 경우, 해당 커널 오브젝트의 상태를 Non-Signaled상태로 변경ㅎ하므로 다른 쓰레드들은 임계 영역으로의 진입이 제한된다. 임계 영역에서 일을 마친 쓰레드가 임계 영역을 빠져나오면서 ReleseMutex함수를 호출한다. 이 함수가 호출되면 뮤텍스는 다른 누군가에게 획득이 가능한 상태 즉 Signaled상태가 되어서 다른 쓰레드의 진입을 허용한다.
* 세마포어 기반의 동기화(커널 모드 동기화): 세마포어는 뮤텍스와 굉장히 유사하다. 뮤텍스는 세마포어의 일종이다. 세마포어는 카운트 기능이 존재하지만 뮤텍스에는 존재하지 않는다. 뮤텍스에는 임계영역에 접근 가능한 쓰레드 개수를 조절하는 기능이 없다. 그러나 세마포어는 가지고 있다. 임계영역의 접근 허용 쓰레드 개수를 하나로 제한하기 위해 사용도되는 세마포어를 가리켜 바이너리 세마포어라 하는데 이렇게 되면 바이너리 세마포어는 뮤텍스와 동일한 기능을 제공하게 된다. 
* 이름있는 뮤텍스 기반의 프로세스 동기화(커널 모드 동기화): 뮤텍스 오브젝트, 세마포어 오브젝트의 생성함수를 자세히 보면 이름을 붙여줄 수 있도록 디자인 되어있다. 뮤텍스에 이름을 붙이면 "이름있는 뮤텍스"라 한다. 그렇다면 어떤 용도로 사용할까? 뮤텍스는 프로세스가 아니라 커널, 즉 운영체제의 소유이다. 따라서 서로 다른 프로세스 영역에 존재하는 쓰레드가 뮤텍스를 이용해서 동기화 하는 상황이 있을수도 있다. 왜냐하면 뮤텍스는 커널 오브젝트이므로 어떤 프로세스의 요청에 의해 만들어졌다 하더라도 그 프로세스의 영역에 존재하는 것이 아니다. 즉 커널이 관리하는 오브젝트이므로 다른 프로세스에서도 접근 가능하다. 
* 이벤트 기반의 동기화(커널 모드 동기화): 실행순서 동기화에 사용

### 멀티프로세스:
* 여러 개의 CPU를 사용하여 여러 프로세스를 동시에 수행하는 것을 의미
* 장점: 여러 프로세스중 하나에 문제가 발생하면 그 프로세스만 죽는 것 이상으로 영향이 확산되지 않는다
* 단점: Context Switching에서 오버헤드가 발생(캐쉬 메모리 초기화등 무거운 작업이 진행), 프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 프로세스 사이에서 공유하는 메모리가 없어 Context Switching이 발생하면 캐쉬에 있는 모든 데이터를 리셋하고 다시 캐쉬 정보를 불러와야 한다 (Context Switching이란 CPU에서 여러 프로세스를 돌아가면서 작업을 처리하는 과정)

### Context Switching:
* 인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고 다른 프로세스를 동작시켜 작업을 처리한 후 이전에 저장된 프로세스 상태 복구

### 멀티 스레드:
* 프로세스 내에서 둘 이상의 스레드가 동시에 작업을 수행하는 것을 의미
* 각 스레드가 자신이 속한 프로세스의 메모리를 공유하므로 시스템 자원의 낭비가 적다
* 하나의 스레드가 작업을 할 때 다른 스레드가 별도의 작업을 할 수 있어 사용자와의 응답성도 좋아짐

### 레지스터:
* CPU가 요청을 처리하는데 필요한 데이터를 일시적으로 저장하는 기억장치

### Critical Section(임계구역)이란:
* 임계구역은 여러 프로세스 혹은 스레드가 작업을 수행하면서 공유된 자원을 건드리게 될 수 있는데, 이때 동기화 처리를 제대로 해주지 않으면 문제가 발생
* 프로그램 코드 상에서 공유 자원에 접근하는 부분을 임계구역이라 한다

Mutual Exclusion(상호배제):
프로세스 P1이 Critical Section에서 실행중이람면 다른 프로세스들은 그들이 가진 Critical Section에서 실행될 수 없다
Progress(진행):
Critical Section에서 실행중인 프로세스가 없고 별도의 동작이 없는 프로세스들만 Critical Section진입 후보로서 참여될 수 있다
Bounded Waiting(한정된 대기):
P1가 Critical Section에 진입 신청 후 부터 받아들여질 때까지, 다른 프로세스들이 Critical Section에 진입하는 횟수는 제한이 있어야 한다
하드웨어 기반 해결책으로써 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section에 진입하는 프로세스는 Lock을 획득하고 Critical Section을 빠져나올 때 Lock을 방출

### 운영체제란:
운영체제는 컴퓨터 시스템의 자원들을 효율적으로 관리하며 사용자가 컴퓨터를 편리하고 효과적으로 사용할 수 있도록 환경을 제공하는 여러 프로그램의 모임

### 일반적인 프로세스 생성 과정
1. PCB가 생성되며 OS가 실행한 프로그램의 코드를 읽어들여 프로세스에 할당된 메모리의 Text segment에 저장한다.
2. 초기화된 전역 변수 및 static 변수를 data segment에 할당.
3. HEAP과 Stack은 초기 메모리 주소만 초기화됨.
4. PCB에 여러 정보가 기록되면 Ready Queue에서 CPU를 할당받기까지 대기한다.

### 커널이란:
소프트웨어가 컴퓨터 시스템에서 수행되기 위해서는 메모리에 그 프로그램이 올라가 있어야 한다 마찬가지로 운영체제 자체도 소프트웨어로서 전원이 켜짐과 동시에 메모리에 올라가야 한다. 하지만 운영체제처럼 규모가 큰 프로그램 모두 메모링에 올라간다면 한정된 메모리 공간의 낭비가 심할것이다 따라서 운영체제 중 항상 필요한 부분만을 전원이 켜짐과 동시에 메모리에 올려놓고 그렇지 않은 부분은 필요할 때 메모리에 올려서 사용하게 된다 이때 메모리에 상주하는 운영체제의 부분을 커널이라 한다 또 이것을 좁은 의미의 운영체제라고도 한다. 즉 커널은 메모리에 상주하는 부분으로써 운영체제의 핵심적인 부분을 뜻한다 

Semaphore:
세마포어는 공유 자원에 여러 프로세스가 접근하는 것을 막는 것을 말한다
세마포어는 이를 위해서 현재 공유 자원의 상태를 나타내는 카운터 변수를 사용하게 된다. 이러한 변수는 실제로 운영체제 혹은 커널에 값으로 저장되며 각 프로세스는 이를 확인할 수 있고 값을 변경할 수도 있게 된다
각각의 프로세스들은 이런 상태값을 확인하여 자원을 즉시 사용할 수 있는 상태라면 즉시 상용할 수 있고 만약에 누군가가 자원을 사용중이라는 것을 인지하게되면 반드시 일정 시간을 기다렸다가 사용하게 된다. 이런 방식을 통해 여러 프로세스가 공유 자원에 한꺼번에 접근하는 것을 막을 수 있다
큰 특징으로는 세마포어는 뒤에 나올 뮤텍스와 다르게 0혹은 1과같은 이진수 외에 더 큰 숫자를 가지게 할 수도 있어서 꼭 1개의 프로세스만이 자원을 점유하지는 않는다 카운터 변수의 값이 해당 공유 자원에 접근할 수 있는 임계치가 되며 이를 조정하여 접근할 수 있는 프로세스의 개수를 통제할 수 있습니다

Mutex:
뮤텍스는 상호 배제를 뜻하는 말로 임계구역을 가지는 쓰레드들의 running time이 서로 겹치지 않도록 해주는 기법 세마포어와 가장 큰 차이점으로는 공유 자원에 접근할 수 있는 대상의 개수 차이 뮤텍스는 1개의 스레드만이 공유 자원에 접근가능
뮤텍스에서는 lock과 unlcok개념을 사용 즉 이진세마포어와 같은 개념, 자원을 점유하고 있는 대상이 lock을 할 수 있는 권한을 가지고 있어서 자원을 점유하기 시작할 때 들어가서 lock을 걸어버린다 이렇게 되면 다른 대상들은 unlock 상태가 될때까지 기다렸다가 나중에 해당 공유 자원에 접근할 수 있게 된다

Semaphore/Mutex:
뮤텍스는 이진 세마포어로 세마포어의 일종 가장 큰 차이점으로는 뮤텍스는 오직 1개의 프로세스 혹은 스레드만이 공유 자원에 접근할 수 있고, 세마포어는 지정된 변수의 값만큼 접근할 수 있다. 또한 세마포어는 운영체제 혹은 커널 단위에서 해당 리소스 변수가 관리되어 현재 공유 자원을 사용 중인 대상 뿐만아니라 다른 프로세스 및 스레드도 잠금 상태를 해제할 수 있지만 뮤텍스는 프로세스 단에서 관리되고 해당 변수(LOCK)을 가지고 있기 때문에 LOCK을 가지고 있는 변수만이 Unlock을 할 수 있다

### 데드락이란
  프로세스가 자원을 얻지 못해 처리를 하지 못하는 상태로 교착상태 라고도 하며 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생
  발생 조건은 어떤 프로세스가 자원을 요청 했을 때 그 시각에 자원을 사용할 수 없는 상황이 발생할 수 있고 그 때는 프로세스가 대기 상태로 들어 가게 된다 대기 상태로 들어간 프로세스들이 실행 상태로 변경 될 수 없을 때 이러한 상황을 교착 상태라 한다

### 스케줄러:
  프로세스를 스케줄링하기 위한 Queue에는 세 가지 종류가 존재한다
* Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
* Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
* Device Queue: Device I/O작업을 대기하고 있는 프로세스의 집합
  각각의 Queue에 프로세스들을 넣고 빼주는 스케줄러에도 세 가지가 존재

### 장기 스케줄러(Queue에 프로세스들을 넣고 빼주는 스케줄러):
* 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 Ready Queue로 보낼지 결정하는 역할

### 단기 스케줄러(Queue에 프로세스들을 넣고 빼주는 스케줄러):
* CPU와 메모리 사이의 스케줄링을 담당
* Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 Running시킬지 결정
* 프로세스에 CPU를 할당(Scheduler Dispatch)
* 프로세스의 상태: Ready -> Running -> Waiting -> Ready

### 중기 스케줄러(Queue에 프로세스들을 넣고 빼주는 스케줄러):
* 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄(Swapping)
* 프로세스에게서 Memory를 Deallocate
* Degree of Multiprogramming제어
* 현 시스템에서 메모리에 너무 많은 프로그램들이 동시에 올라가는 것을 조절하는 스케줄러
* 프로세스 상태: Read -> Suspended

### CPU 스케줄러:
* 스케줄링 대상은 Ready Queue에 있는 프로세스들이다

* FCFS(First Come First Served):
  먼저 온 순서대로 처리, 비선점형 스케줄링, 일단 CPU를 잡으면 CPU Burt가 완료될 때까지 CPU를 반환하지 않는다. 할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다
  문제점: Convoy Effect(소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생)

* SJF(Shortest Job First):
  다른 프로세스가 먼저 도착했어도 CPU Burst Time이 짧은 프로세스에게 선 할당
  비선점형 스케줄링
  문제점: Starvation(효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별 받으면 안되는것)
  이 스케줄링은 극단적으로 CPU사용이 짧은 job을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU를 할당 받을 수 없다

* SRTF(Shortest Remaining Time First):
  새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
  선점형 스케줄링
  현재 수행중인 프로세스의 남은 Burt Time보다 더 짧은 CPU Burt Time을 가지는 새로운 프로세스가 도착하면 CPU를 뺏긴다
  문제점: Starvation(새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU Burst Time(CPU사용시간)을 측정할 수가 없다

* Priority Scheduling:
  우선순위가 가장 높은 프로세스에게 CPU를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다
  선점형 스케줄링 방식: 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점한다
  비선점형 스케줄링 방식: 더 높은 우선순위의 프로세스가 도착하면 Ready Queue에 넣는다
  문제점: Starvation(무기한 봉쇄, 실행할 준비는 되어있으나 CPU를 사용못하는 프로세스를 CPU가 무기한 대기하는 상태)
  해결책: Aging(아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여준다)

* Round Robin:
  현대적인 CPU스케줄링
  각 프로세스는 동일한 크기의 할당 시간을 갖게 된다
  할당 시간이 지나면 프로세스는 선점당하고 Ready Queue의 제일 뒤에 가서 줄을 선다
  RR은 CPU사용 시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
  RR이 가능한 이유는 프로세스의 Context를 Save할 수 있기 때문이다
  장점: Response Time이 빨라진다: n개의 프로세스가 Ready Queue에 있고 할당시간이 q인경우 각 프로세스는 q단위로 CPU시간의 1/n을 얻는다. 즉 어떤 프로세스도 (n-1)q time unit이상 기다리지 않는다
  프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가한다. 공정한 스케줄링이라고 할 수 있다
  주의할점: 설정한 time quantum이 너무 커지면 FCFS와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 Context Swtich로 Overhead가 발생한다 그렇기 때문에 적당한 Time Quantum을 설정하는것이 중요

### 동기와 비동기의 차이
  일반적으로 동기와 비동기의 차이는 메소드를 실행시키면 동시에 반환 값이 기대되는 경우를 동기라고 표현하고 그렇지 않은 경우에 대해서 비동기라고 표현한다 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미한다. 비동기의 경우 blocking되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

스레드safe란:
페이지 교체 알고리즘:

### HTTP: 
* 텍스트 기반의 통신 규약으로 인터넷에서 데이터를 주고받을 수 있는 프로토콜
* 동작: 클라이언트 즉 사용자가 브라우저를 통해서 어떠한 서비스를 url을 통하거나 다른 것을 통해서 요청을 하면 서버에서는 해당 요청사항에 맞는 결과를 찾아서 사용자에게 응답하는 형태로 작동
* HTML문서만이 HTTP통신을 의한 유일한 정보 문서는 아니다 Plain text로 부터 JSON데이터 및 XML과 같은 형태의 정보도 주고 받을 수 있으며 보통은 클라이언트가 어떤 정보를 HTML형태로 받고 싶은지, JSON형태로 받고 싶은지 명시해주는 경우가 많다
* 특징: HTTP 메시지는 HTTP 서버와 HTTP클라이언트에 의해 해석이 된다. TCP/IP를 이용하는 응용 프로토콜이다 HTTP는 연결 상태를 유지하지 않는 비연결성 프로토콜이다 HTTP는 연결을 유지하지 않기 때문에 요청/응답 방식으로 동작한다

### TCP: 
* 신뢰성이 없는 인터넷을 통해 종단간에 신뢰성있는 바이트 스트림을 전송 하도록 특별히 설계되었다
* tcp에서 연결 설정은 3way handshake를 통해 행해진다

### 3way handshake:서버와 클라이언트 연결을 사전에 세션을 수립하는 과정
  1.  클라이언트는 서버에 요청하는 syn패킷을 보내고 syn/ack응답을 기다리는 상태
  2.  서버는 syn요청을 받고 클라이언트에게 요청을 수락한다는 ack와 syn flag가 설정된 패킷을 발송하고 클라이언트가 ack으로 응답하기를 기다린다 syn_received상태가 된다
  3.  클라이언트는 서버에게 ack를 보내고 이후로 연결이 이루어지고 데이터가 오가게 되는것

### 4way handshake:서버와 클라이언 연결을 해제 하는데 필요한 프로세스
  1.  클라이언트에서 서버와의 연결 종료를 위해 서버에 fin패킷을 보내고 fin wait상태가 된다
  2.  서버는 클라이언트로부터 fin을 받고 응답 패킷 ack를 보낸다 close_wait상태
  3.  서버가 통신이 끝나면 연결을 종료할 준비가 되면 클라이언트에게 fin패킷을 보내고 last_wait상태가 된다
  4.  클라이언트는 확인 패킷 ack를 보내고 time_wait상태가 된다

### UDP:
* ip데이터그램을 캡슐화하여 보내는 방법과 연결 설정을 하지 않고 보내는 방법을 제공
* 코드가 간단할 뿐만 아니라 tcp처럼 초기설정에서 요구되는 프로토콜보다 적은 메세지가 요구된다

### 대칭키:
* 둘 혹은 그 이상의 사용자 사이에 공유된 단일 키를 의미

### 웹 브라우저에 url을 입력했을 때 일어나는 현상:
  브라우저는 입력한 url을 활용하여 해당 웹사이트의 서버와 통신하여 웹사이트의 내용을 우리에게 보여주게 된다. 브라우저의 입장에서는 입력된 url내에서 필요한 모든 정보를 파악해야 한다. url은 protocol, url, port로 이루어져 있다(protocol:네트워크 상으로 통신할 때 어떤 프로토콜을 사용하여 url에 요청할건지)(url:해당 웹사이트의 위치를 식별)(port: 논리적 접속장소를 알려줌)
  
  사실 protocol과 port를 제외하고 url만 입력해도 브라우저에서 protocol부분과 port부분을 제공 해준다. url부분을 도메인이라고 말하는데 도메인만을 입력하여 웹사이트에 접속하였을 때 브라우저는 기본 세팅으로 http프로토콜을 사용하여 접속을 시도한다. 만약 https프로토콜이 적용된 사이트라면 http접속이 시도되었을때 301 302 http 상태코드를 통해 리다이렉트를 하라는 메세지를 브라우저에 보내고 브라우저는 이 요청을 통해 해당 사이트에 https프로토콜로 접속한다.port는 명시적으로 선언하지 않더라도 브라우저에서 설정된 기본값을 이용해 요청하게 된다. 만약 url의 구조가 문법에 맞지 않는다면 입력을 웹 브라우저의 기본 검색엔진으로 검색을 요청한다. 
  
  도메인 네임은 우리가 해당 사이트를 쉽게 접근할 수 있도록 편의성을 위해 만들어진 주소이다. 실제로 모든 인터넷 주소는 ip로 이루어져있는데 도메인 네임으로는 컴퓨터끼리 통신할 수 없기 때문에 ip로 변환해줘야 하는데 브라우저는 자신의 로컬 hosts파일과 브라우저 캐시에 해당 url이 존재한다면 바로 접속하고 없다면 dns서버에 요청하여 해당 url ip주소로 변환한다

### HTTP통신과 소켓통신:
  HTTP통신은 html파일을 전송하는 프로토콜 현재는 json image파일 또한 전송가능 http통신은 클라이언트에서 서버로 요청을 보내고 서버가 응답하는 방식으로 통신이 이루어진다. 응답에는 클라이언트의 요청에 따른 결과를 반환한다.
  
  소켓이란 두 프로그램이 서로 데이터를 주고 받을 수 양쪽에 생성되는 통신 단자이다. 소켓 통신이란 서버와 클라이언트 양방향 연결이 이루어지는 통신으로 클라이언트도 서버로 요청을 보낼 수 있고 서버도 클라이언트로 요청을 보낼 수 있는 통신으로 양쪽에서 서로에게 데이터 전달을 하는 양방향 통신이다. 즉 자주 데이터를 주고 받는 환경이 아닌 경우 http통신을 통해 받는것이 유리하다. 자주 주고받고하는 환경에서는 소켓 통신이 유리

### SSL이란:
  암호화 기반 인터넷 보안 프로토콜 인터넷 통신의 개인정보 보호, 인증, 데이터 무결성을 보장

### DNS란:
  도메인 네임 시스템의 약자. 도메인이란 인터넷에 연결되어 있는 장치들은 각각의 장치를 식별할 수 있는 주소를 가지고 있는데  ip주소는 숫자형식으로 되어있어 사람이 기억하기 어렵다 이러한 숫자들을 기억하기 쉽게 이름을 부여하는것

### DNS서버를 만드는 이유:
  기관 등의 내부 네트워크가 클 경우 dns서버가 내부에 있을 경우 캐쉬 효과가 있다 그리고 서비스 제공을 목적일 경우 직접 dns서버를 운영하게 되면 동적으로 dns레코드를 관리 할 수 있다는 장점이있다

### DNS 서버를 Centralize하게 만들지 않는이유:
  도메인 수가 너무 많기 때문에 dns서버 종류를 계층화해서 단계적으로 처리한다. 특히 도메인의 총 관리는 ICANN에서 하기 때문에 dns서버도 최상위 도메인에서 개인 도메인의 서브 도메인까지 도메인 이름의 분류와 마찬가지로 디렉토리/계층 형태로 구분된다

### GET/POST 차이:
  GET방식은 요청하는 데이터가 http request message의 header 부분에 url?뒤에 데이터가 붙어 request를 보낸다. url이라는 공간때문에 데이터의 크기가 제한적이고 데이터가 url에 그대로 노출된다. GET은 가져오는것이다 서버에서 어떤 데이터를 가져와서 보여준다거나 하는 용도, SELECT적인 성향
  GET방식은 브라우저에서 캐싱할 수 있다 때문에 GET방식으로 요청한다면 기존에 캐싱되었던 데이터가 응답될 가능성이 존재한다
  POST방식은 http request. message의 body부분에 데이터가 담겨서 전송된다. POST는 서버의 값이나 상태를 변경하기 위해서 또는 추가하기 위해서 사용

### 캐싱이란:
* 잠시 저장해둔다는 의미, 캐시 메모리라고 하면 실제 메모리와 cpu사이에서 빠르게 전달을 위해서 미리 데이터들을 저장해두는 좀더 빠른 메모리 네트워크에서는 캐시는 로컬에 파일을 미리 받아놓고 그 내용을 보거나 웹서버에서도 매번 로딩을 해야 하는 파일들을 미리 로딩해두고 응답을 준다

### 프록시 서버:
* 클라이언트와 서버 사이에서 데이터를 전달해 주는 서버, 프록시 서버는 프록시 서버에 요청된 내용들을 캐시를 이용하여 저장
* 프록시 서버에서는 데이터를 암호화 하지 않음
* 정보를 암호화 하려면 VPN을 사용해야함

### scale-up/scale-out 차이:
* 스케일 아웃: 접속된 서버의 대수를 늘려 처리 능력을 향상키시는것
* 스케일 업: 서버 그 자체를 업그레이드해 처리 능력을 향상시키는것

### 로드밸런싱이란:
* 서버에 가해지는 부하를 분산 해주는 장치나 기술

### 로드 밸런싱 알고리즘:
* 라운드로빈: 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식
* 가중 라운드로빈: 각 서버에 가중치를 매기고 가중치가 높은 서버에 요청을 우선적으로 배정하는 방식
* 최소 연결 방식: 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 트래픽을 배정하는 방식
* ip해시방식: 클라이언트의 ip주소를 특정 서버로 매핑하여 요청을 처리하는 방식

### L4로드 밸런싱:
  TCP UDP 포트정보를 바탕으로 한다, 데이터 안을 보지 않고 패킷 레벨에서만 로드를 분산하기 때문에 속도가 빠르고 효율이 높음, 섬세한 라우팅이 불가능하지만 L7로드 밸런서보다 저렴

### L7로드 밸런싱:
  HTTP헤더 쿠키 등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽을 분산하는 것이 가능하다. 즉, 패킷 내용을 확인하고 그 내용에 따라 로드를 특정 서버에 분배하는 것이 가능. 더 섬세한 라우팅이 가능하고 비정상적인 트래픽을 필터링 할 수 있다, 패킷의 내용을 복호화 해야하기 때문에 많은 비용이 든다

### Flow Control정의와 방식:
  송신측과 수신측의 데이터처리 속도 차이를 해결하기 위한 기법이다
* Stop and Wait: 
  매번 전송한 패킷에 대해 확인응답을 받아야만 그 다음 패킷을 전송
* Sliding Window: 
  이를 위해서 tcp는 슬라이딩윈도우라는 기법을 도입하게 된다 창의 크기를 가변적으로 조절하여 필요에 따라서 창의 크기를 크게해서 여러 패킷을 논리적인 하나의 패킷으로 묶어 전송하고자한다
  윈도우의 크기 결정: 수신자가 받을 수 있는 윈도우크기(rwnd)와 송신자가 보낼 수 있는 패킷 크기의 한계(cwnd) 중 더 작은 값을 고른다
* Congestion Control: 
  송신측의 데이터 전달과 네트워크의 처리속도 차이를 해결하기 위한 기법
  송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다 하지만 이러한 네트워크 상의 라우터가 항상 한가로운 상황은 아니다 만약 한 라우터에 데이터가 몰릴 경우 다시 말해 혼잡할 경우 라우터는 자신에게 온 데이터를 모두 처리할 수 없다 그렇게 되면 호스트들은 또 다시 재전송을 하게 되고 결국 혼잡을 가중시켜 오버플로우나 데이터 손실을 발생시킨다 따라서 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송 속도를 강제로 줄이게 된다
* Slow Start: 윈도우 크기를 2배로 늘린다 그러다가 혼잡현상이 발생하면 창 크기를 1로 떨어뜨린다 그 후 혼잡현상이 발생했던 창 크기는 절반까지는 이전처럼 지수 함수 꼴로 창 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시킨다
* Fast Recovery: 혼잡한 상태가 되면 창 크기를 1로 줄이지 않고 반으로 줄이고 선형 증가시키는 방식

# Nginx

## 기초지식
 Nginx는 1개의 마스터 프로세스(master process)와 여러개의 워커 프로세스들을 가지고 있다. 마스터 프로세스의 주요 역할은 설정(configuration)을 읽고 평가하고, 워커 프로세스들을 관리하는 것이다. 반면 워커 프로세스들의 역할은 실질적인 요청들(requests)를 처리하는 것이다. Nginx는 이벤트 기반 모델(Event-Driven Architecture)사용하며, 운영체제 의존적인 메커니즘을 활용하여 워커 프로세스들 사이의 요청을 효율적으로 분배 한다. 워커 프로세스의 개수는 설정파일(configuration)안에 정의되어 있는데, 설정에 따라 절대적인 개수로 고정될 수도 있고 또는 가용한 CPU 코어의 개수에 따라 자동으로 조절될 수도 있다. Nginx와 그 모듈들이 동작하는 방식은 설정파일안에서 결정된다. 디폴트로는 그 설정파일 이름은 nginx.conf로 되어 있으며 그 파일이 위치하는 디렉토리는 /usr/local/nginx/conf, /etc/nginx 또는 /usr/local/etc/nginx이다.
nginx를 시작하기 위해서는 우선 실행파일(executable file)을 실행한다. nginx가 시작되면 실행파일을 -s파라미터와 함께 실행하여 컨트롤할 수 있다.
```
nginx -s [signal]
```
* signal의 종류: 
 stop: 빠른종료(Fast Shutdown)
 quit: 우아한 종료(Graceful Shutdown)
 reload: 설정파일(configuration file)다시 로딩하기
 reopen: 로그 파일 열기
 
 예를 들어 nginx를 종료할 때. 워커 프로세스들이 현재 처리하고 있는 요청들을 모두 완료할 때까지 기다리고 싶을 때는 다음과 같은 명령을 사용한다. nginx -s quit 이 명령은 nginx를 실행시킨 유저와 동일한 유저에 의해 실행되어야 한다. 만약 nginx를 실행한 유저가 root유저일 경우 권한 획득을 위해 sudo명령을 함깨 사용한다.
설정파일이 변경되었을 경우 nginx에 reload명령을 보내거나 nginx를 재시작하기 전까지는 변경된 설정은 적용되지 않는다. 
```
nginx -s reload 
```
 마스터 프로세스가 reload시그널을 전달받은 경우 그것은 우선 새로운 설정 파일의 문법 유효성 검사를 마친 뒤 새로운 설정을 적용한다. 만약 문법 검사에서 이상이 없을 경우 마스터 프로세스는 새로운 설정을 적용한다. 만약 문법 검사에서 이상이 없을 경우 마스터 프로세스는 새로운 워커 프로세스들을 실행시키고 예전 워커 프로세스들에게는 메시지를 보내 종료 요청을 한다. 예전 워커 프로세스들은 종료 요청을 받으면 더 이상 새로운 요청은 거부하고 기존에 처리하던 요청들을 마무리한 뒤 종료 한다.
하지만 문법 검사에 이상이 있거나 오류가 발생했을 경우에는 마스터 프로세스는 변경 내용을 ROLL BACK하고 이전 설정으로 계속 작업한다. signal은 PID를 이용해 프로세스에게 직접 전달된다, 그 nginx 마스터 프로세스의 PID는 기본적으로 /usr/local/nginx/logs 또는 /var/run디렉토리에 있는 nginx.pid파일에 쓰여있다. 만약 마스터 프로세스의 프로세스 ID가 1628일 경우 nginx에게 우아한종료(graceful shutdown)요청을 보내기 위해서는 다음과 같이 명령을 사용할 수 있다. 
```
kill -s quit 1628
```
실행 중인 모든 nginx 프로세스들의 목록을 얻기 위해서는 ps 유틸리티를 사용하여 다음과 같은 명령을 사용한다. 
```
ps -ax | grep nginx
```
* 설정파일 구조
 nginx는 여러 개의 모듈들로 구성되어 있는데, 그것들은 설정파일 안의 디렉티브(directives)에 의해 제어된다. 디펙티브들은 심플 디렉티브(simple directives)와 블록 디렉티브(block directives)로 나뉜다. 심플 디렉티브의 이름과 파라미터는 스페이스엥 의해 구분되고 세미콜론(;)으로 끝난다. 블록 디렉티브는 심플 디렉티브와 기본적으로 동일한 구조를 가지는데 하지만 세미콜론 대신에 그것은 중괄호(braces)로 둘러싸인 추가적인 명령들의 집합이 뒤에 붙는다. 그리고 만약 블록 디렉티브가 중괄호 안에 다른 디렉티브를 가질 수 있으면 그것은 컨텍스트(context)라고 불린다(e.g events,http.server그리고 location등). 설정파일 안에서 다른 컨텍스트 밖에 있는 디렉티브들은 모두 메인 컨텍스트안에 있는 것으로 본다. events와 http디렉티브는 메인 컨텍스트 안에 있는 것이고, server 디렉티브는 http컨텍스트 안에 그리고 location 디렉티브는 server컨텍스트 안에 있는 것이다. 그리고 #기호 이후에 오는 모든 줄은 주석으로 간주한다.
 
* 정적 컨텐트 서빙
 웹 서버의 중요한 업무는 파일들(images 또는 정적 HTML pages등)을 서빙하는 것이다. 이제 우리는 서버에 들어오는 요청에 따라서 서로 다른 로컬 디렉토리들(/data/www(HTML파일 디렉토리), /data/images(이미지 파일 디렉토리))에 있는 파일들이 서빙되는 예제를 살펴보자 이를 위해서 설정파일을 수정해야하는데 http블록 안에 server 블록을 설정하고 그 server블록 안에는 두 개의 location블록들을 설정할 것이다. 우선 /data/www 디렉토리를 생성하고 그 안에 index.html파일을 만들고 아무런 텍스트 내용을 작성한다. 그리고 /data//images/ 디렉토리를 만들고 그 안에 몇 장의 이미지 파일들을 넣는다. 그 당음 설정파일을 연다. 디폴트 설정파일안에는 이미 몇 개의 server블록에 대한 예제들이 있는데 대부분은 주석으로 처리되어있다. 다른 모든 블록들을 주석으로 처리하고 새로운 server블록을 다음과 같이 작성한다. 
```
http {
	 server{
	}
        }
```
 일반적으로 설정파일 안에는 여러개의 server블록들을 포함할 수 있는데, 그것들은 사용하는 포트번호 또는 서버이름에 따라 나뉘어져 있다. 어떤 요청이 들어오면 nginx는 우선 어떤 server블록이 해당 요청을 처리할지 결정하고 그 다음은 요청 헤더에 있는 URI를 server블록 안의 location 디렉티브들의 파라미터와 대조하여 검사한다. Server 블록 안에 다음의 location 블록을 추가한다.
```
	location / {
		root /data/www;
	}
 ```
 위의 location블럭은 요청에서 URI와 비교하여 “/“프리픽스를 나타낸다. 매칭되는 요청에 대해서 root디렉티브에 설정된 경로(path)에 해당 URI가 붙여진다. 즉 /data/www에 붙여져서 로컬 파일 시스템에 있는 요청된 파일에 대한 경로를 형성한다. 만약 location블록들 중ㅇ에 매칭되는 것이 여러개 있다면 nginx는 그 중 가장 긴 프리픽스를 가진 것을 선택한다. 위의 location 블록은 길이 1의 가장ㅇ 짧은 프리픽스를 제공한다. 따라서 다른 모든 location블록들ㅇ이 매칭ㅇ에 실패할 경우 이 블록이 사용될 것이다. 다음 location블록을 추가해보자
```
	location /images/ {
		root /data;
	}
 ```
 위의 location블록은 /images/로 시작하는 요청에 대해 매치가될 것이다. location / 블록에도 역시 매치될 것이지만 이것은 가장 짧은 길이의 프리픽스이다. 현재까지 작성된 server블록은 이렇다
```
	server {
		location / {
			root /data/www;
		}
		location /images/ {
			root /data;
		}
```
 이것은 이미 80포트에서 듣고 있는 서버로 동작하는 설정파일이며 그것은 로컬 머신에서 http://localhost/로 접속이 가능하다. 그리고 /images/로 시작ㄱ하는 URI를 가진 요청에 대해서는 서버는 /data/images디렉토리에서 파일을 전송할 겉이다. 예를 들어 http://localhost/images/example.png 요청에 대한 응답으로는 nginx는 /data/images/example.png 파일을 전송할 것이다. 만약 그 파일이 존재하지 않을 경우 nginx는 404오류(Not Found)를 전송할 것이다. 그리고 /images/로 시작하지 않는 URI를 가진 요청은 /data/www 디렉토리로 맵핑될 것이다. 예를 들어서 http://localhost/some/example.html요청에 대한 응답으로는 nginx는 /data/www/some/example.html 파일을 전송할 것이다. 새로운 설정파일을 적용하기 위해서 아직 nginx를 실행하지 않았으면 nginx를 시작시키고 이미 실행중인 경우 다음과 같이 reload시그널을 마스터 프로세스에 전송한다. nginx -s reload 
만약 어떤 것이 예상대로 동작하지 않을 경우 /usr/local/nginx/logs또는 /var/log/nginx 디렉토리 안에 있는 access.log 또는 error.log파일을 확인해 볼 수 있다.

* 프록시 서버 세팅
 nginx의 가장 흔한 사용 중 하나는 그것을 프록시 서버로 사용하는 것이다. 따라서 프록시 서버는 요청을 받으면 프록시된 다른 서버에게 요청을 전달하고, 그들에게 받은 응답을 결과적으로 클라이언트에게 전송한다. 우리는 기본적ㅇ인 프록시 서버를 하나 설정할 것인데 그것은 로컬 디렉토리에 있는 이미지 파일에 대한 요청을 처리하고 나머지 모든 요청들은 프록시된 서버에게 전달한다. 예제를 봐보자 우선 프록시된 서버를 하나 정의할 것인데 다음과 같이 설정파일에 하나의 server블록을 추가 한다.
```
	server {
		listen 8080;
		root /data/up1;
		location / {
		}
	}
```
 이것은 포트 8080을 듣고 있는 간단한 서버가 될 것인데 이. 서버는 모든 요청을 로컬 파일 시스템의 /data/up1디렉토리로 맵핑할 것이다. 따라서 /data/up1 디렉토리를 생성하고 이 안에 새로운 index.html파일을 ㅁ만들어 넣도록. 한다. 이때 잘 보앙야 할 것은 root 디렉티브가 server컨텍스트 안에 위치한다는 점이다. 그러한 root 디렉티브는 어떤 요청에 대해 선택된 location블록이 자체적인 root 디렉티브를 갖고 있지 않을 때 사용된다. 다음으로 이전에 작성했던 server 설정파일ㅇ을 수정하여 프록시 설정파일로 만들어 보자 첫 번째 location블록에는 proxy_pass디렉티브와 함께 프록시된 서버의 프로토콜 이름 포트 번호를 파라미터에 명시된대로 넣어준다.
 ```
	server {
		location / {
			proxy_pass http://localhost:8080;
		}
		location /images/ {
			root /data;
		}
	}
 ```
 그리고 두 번째 location 블록을 수정하여 특정 파일 확장자를 가진 이미지 요청에 대해 매치되도록 만든다.
 ```
	location ~ \.(gif|jpg|png)$ {	
	root /data/images;
	}
 ```
 위의 파라미터는 정규식표현이며 이것은 .gif, .jpg, .png로 끝나는 모든 URI와 매치된다. 정규식 표현은 반드시 ~ 심볼을 앞에 붙여야한다. 이에 해당하는 요청들은 모두 /data/images 디렉토리로 맵핑될 것이다. nginx가 요청을 처리하기 위해 어떤 location블록을 선택할 때는 우선 각 location디렉티브의 프리픽ㄱ스를 검사하고 매치되는 가장 긴 프리픽스를 가진 하나의 location블록을 기억해둔다. 그 다음으로 정규식을 검사한다 만약 매치되는 정규식이 ㅇ있을 경우 그 location을 선택하게 되고 매치되는 정규식이 없을 경우 이전에 기억해두었던 location블록을 선택하게 된다.
지금 까지 완성된 프록시 서버의 설정파일ㅇ은 다음과 같다.
```
	server {
		location / {
			proxy_pass http://localhost:8080;
		}
		location ~ \.(gif|jpg|png)$ {	
			root /data/images;
		}
	}
 ```
 이 서버는 .gif, .jpg, .png로 끝나는 모든 요청을 필터링하여 /dataa/images 디렉토리로 맵핑할 것이다. 그리고 다른 모든 요청들은 위에 설정한 프록시된 서버로 전달될 것잉다. 새로운 설정파일ㅇ을 적용ㅇ하기 위해 reload시그널을 마스터 프로세스에 전송한다. nginx -s reload
FastCGI 프로시 세팅
nginx는 요청들을 다양한 프레임워크와 PHP와 같은 프로그래밍 언어로 빌드된 ㅇ어플리케이션을 실행하는 FastCGI서버들로 라우트하기 위해 사용될 수 있다. FastCGI서버와 함께 동ㅇ작하기 위한 가장ㅇ 기본적ㅇ인 nginx설정은 proxy_pass대신에 fastcgi_pass디렉티브를 사용하는 것이다. 그리고 FastCGI서버에 전달되는 파라미터를 설정하기 위해서 fastcgi_param 디렉티브를 사용한다. FastCGI서버가 localhost:9000에 접속가능하다고 가정ㅇ해보자. 이전의 프로시 설정ㅇ을 기본으로 해서 proxy_pass 디렉티브를 fastcgi_pss디렉티브로 교체하고 파라미터를 localhost:9000로 설정한다. PHP에서는 SCRIPT_FILENAME파라미터는 스크립트 이름을 결정하기 위해 사용되며, QUERY_PARAMETER는 요청 파라미터를 전달하기 위해 사용된다. 
```
	server {
		location / {
			fastcgi_pass localhost:9000;
			fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
			fastcgi_param QUERY_STRING $query_string;
		}
		location ~ \.(gif|jpg|png)$ {	
			root /data/images;
		}
	}
 ```

 위의 설정은 정적 이미지에 대한 요청을 제외한 모든 요청들을 localhost:9000에서 동작 중인 프록시된 서벙에게 FastCGI프로토콜을 사용해 라우트 할 것이다.

## Nginx & Aapache:
### Apache: MPM 방식으로 HTTP요청을 처리
 MPM(Multi-Process Module)에는 PreFork방식 Worker방식이 있다.
 
* PreFork MPM:
	Client 요청에 대해 Apache 자식 프로세스를 생성하여 처리
	요청이 많을 경우 Process를 생성하여 처리
	하나의 자식프로세스당 하나의 스레드를 갖는다(최대1024개)
	스레드간 메모리 공유 하지 않는다. 이 방식은 독립적이기에 안정적인 반면 메모리 소모가 크다
	
* Worker MPM:
	PreFor보다 메모리 사용량이 적고 동시접속자가 많은 사이트에 적합하다. 각 프로세스의 스레드를 생성해 처리하는 구조
	스레드간 메모리 공유 가능
	프로세스 당 최대 64개의 스레드처리가 가능하며 각 스레드는 하나의 연결만을 부여받음
	
한계: 클라이언트 접속마다 Process혹은 Thread를 생성하는 구조이다. 1만 클라이언트로부터 동시접속 요청이 들어온다면 CPU와 메모리 사용량이 증가하고 추가적인 Process/Thread 생성비용이 드는 등 대용량 요청에서 한계를 보인다 또한 Apache 서버의 프로세스가 blocking될 때 요청을 처리하지 못하고 처리가 완료될 때까지 대기상태에 있는다. 이는 Keep Alive(접속대기)로 해결이 가능하지만 효율이 떨어진다.

### Nginx: Apache의 C10K(한 시스템에 동시 접속자수가 1만명이 넘어갈 때 효율적방안) Event-Driven 구조의 웹서버. Event-Driven방식으로 작동. 즉 프로그램 흐름이 이벤트에 의해 결정된다. 한 개 또는 고정된 프로세스만 생성하고 그 내부에서 비동기로 효율적인 방식으로  task를 처리합니다. Apache와 달리 동시접속자 수가 많아져도 추가적인 생성비용이 들지 않는다.

* 비동기 이벤트 기반으로 요청하여 적은양의 스레드가 사용되기 때문에 CPU소모가 적다.
* Apache와 달리 CPU와 관계없이 I/O들을 전부 Event Listener로 미루기 때문에 흐름이 끊이지 않다.
* Context Switching 비용이 적다.

결론: Apache는 Nginx에 비해 모듈이 다양하다, Apache의 안정성, 확장성, 호환성을 장점으로 들자면 Nginx는 성능이 우세하다는 장점이 있다.

Context: 스레드가 작업을 진행하는동안 작업정도 (레지스터, 커널스택, 사용자스택 등)을 보관 OS는 A작업을 진행할 때 A스레드의 Context를 읽어오며 B스레드로 전환 할 때 A스레드의 Context를 저장하고 B스레드의 Context를 읽어오는 일련의 반복작업을 한다. 즉 스레드 개수가 많아질 수록 Context Switching작업은 더 빈번하게 일어나고 이 때문에 성능이 저하될 수 있다.

# 이벤트 기반 아키텍처:
이벤트란 시스템 하드웨어 또는 소프트웨어 상태의 변화 또는중대 사건의 발생을 의미한다. 이벤트는 시스템의 다른 부분에 이벤트가 발생했음을 알리기 위해 해당 시스템에서 보내는 메시지 또는 알림을 뜻하는 이벤트 알림과는 다르다. 이벤트소스는 내부 또는 외부 입력일 수 있다. 이벤트는 마우스 클릭이나 키보드 입력과 같은 사용자 또는 센서 출력과 같은 외부 소스에서 생성되거나 프로그램 로딩과 같이 시스템에서 비롯될 수 있다.

이벤트 기반 아키텍처는 이벤트 생성자와 이벤트 소비자로 구성되어 있다. 이벤트 생성자는 이벤트를 감지하며 메시지로 해당 이벤트를 나타낸다. 생성자는 이벤트 소비자 또는 이벤트 결과를 알지 못한다. 이벤트가 감지된 후에는 이벤트 처리 플랫폼이 이벤트를 비동기식으로 처리하는 이벤트 채널을 통해 해당 이벤트 생성자에서 이벤트 소비자로 전송됩니다. 

이벤트 발생 시 이벤트 소비자는 알림을 받아야 하며, 이벤트를 처리할 수도 있고 이벤트의 영향을 받기만 할 수도 있습니다. 이벤트 처리 플랫폼은 올바른 응답을 실행하고 적합한 소비자에게 활동을 다운스트림으로 전송한다. 다운스트림 활동은 이벤트 결과가 나타나는 위치이다. 복잡성과 역동성에 가장 효율적으로 대응할 수 있는 모델이다. 시시각각 발생하는 이벤트의 생성과 감지, 반응을 중심으로 구축되는 모델이기 때문이다. 프로그램이 어떤 유저액션(이벤트)에 대한 반응으로 동작하는 패턴이다.

 
 # MSA
 
### MSA란:
 애플리케이션을 구성하는 서비스들을 독립적인 단위로 분해하여 구축하고 각 구성 요소들을 네트워크로 통신하는 아키텍쳐로 서비스 안정성과 확작성을 지원
 단일 프로그램을 컴포넌트 별로 나누어 작은 서비스의 조합으로 구축하는 방법, 각 컴포넌트는 서비스 형태로 구현되고 API를 이용하여 타 서비스와 통신하게 됨

### 모놀리식 아키텍처 단점:
 모놀리식 아키텍처는 소프트웨어의 모든 구성요소가 한 프로젝트에 통합되어 있는 형태, 웹 개발을 예로 들면 웹 프로그램을 개발하기 위해 모듈별로 개발하고 개발 완료된 웹 어플리케이션을 하나의 결과물로 패키징하여 배포되는  형태인데 부분장애가 전체 서비스의 장애로 확장될 가능성, 부분적인 Scale Out이 어렵고 서비스 변경 및 수정시 장애 파악이 어렵다. 현 프레임워크와 언어에 종속적이다

### MSA 장점:
 MSA는 API를 통해서만 상호작용할 수 있다. 즉 서비스의 접근점 end-point를 API형태로 외부에 노출하고 실질적인 세부 사항은 모두 추상화한다. 내부의 기술적인 사항들은 서비스 API에 의해 가려진다
 애플리케이션은 항상 기술 중립적 프로토콜을 사용해 통신하므로 서비스 구현 기술과는 무관하다. 따라서 마이크로서비스 기반의 애플리케이션을 다양한 언어와 기술로 구축가능
 마이크로서비스는 SOA에서 사용되는 집중화된 관리 체계를 사용하지 않는다. 마이크로서비스 구현체의 공통적인 특징 중 하나는 ESB(Enterprise Service Bus)와 같은 무거운 제품에 의존하지 않는다는 점이다. REST 등 가벼운 통신 아키텍처등을 이용한 Message Stream을 주로 사용한다
 각각 서비스 부하에 따라 개별적으로 Scale Out이 가능하다
 서비스 별로 독립적 배포가 가능하다. 지속적인 배포(CD)도 쉬워짐
 각각의 서비스는 모듈화가 되어 있고 모듈끼리 RPC또는 Message-Driven API등을 이용하여 통신한다. 이러한 MSA는 각각 개별의 서비스 개발을 빠르게 하며 유지보수도 쉽게 가능하다

### MSA 단점:
 모놀리식에 비해 상대적으로 많이 복잡하다. 서비스가 모두 분산되어 있어서 내부 시스템의 통신을 어떻게 할 것인지 정해야하고 통신 장애나 서버 부하 등이 발생할 경우 트랜잭션 유지 방법을 결정하고 구현해야한다.
 모놀리식에서는 단일 트랜잭션을 유지하면 되지만 MSA에서는 DB마다 서비스가 달라 트랜잭션 유지가 어렵다.
 통합 테스트가 어렵다 개발 환경과 실제 운영환경을 동일하게 가져가는 것이 쉽지 않다.
 배포 시 다른 서비스들과 연동을 고려해야 한다.

### MSA 단점 보안방법:
 장애추적, 모니터링, 메시징이 어렵다 -> Sleuth, ELK, EFK등의 서비스를 연동하여 사용하는 방안 고려
 여러 서비스에 걸쳐져 있는 feature의 경우 트랜잭션을 다루기 어렵다 -> 보상 트랜잭션 또는 부분적으로 composite 서비스로의 병합 고려
 여러 서비스에 걸쳐져 있는 feature의 경우 테스팅이 복잡하다 -> 테스팅 계획 및 방법에 노력 투자
 서비스간 dependency가 있는 경우 릴리즈가 까다롭다 -> 관련 개발조직 간 roll-out 계획 마련 및 dependency의 명백한 관리
 서비스 개수가 많고 유동적이기 때문에 CI/CD 및 서비스 관리 상의 문제가 발생할 수 있다 -> 서비스 레지스트리, 모니터링, 개발~디플로이 자동화 기술 고려(PaaS고려)
 Monolith로 시작한 시스템을 MSA로 전환 할 때 큰 고통이 수반 -> B2C웹 또는 SaaS어플리케이션은 처음부터 MSA및 서비스 별 조직 구성 고려

### EFK 구성 설계:
 EFK: ElasticSearch + FluentD + Kibana조합
 ElasticSearch는 실시간 검색/분석 기능을 제공하고, 분산환경에 저장되어 있는 로그를 통합으로 수집함으로써 통합 저장소의 역할을 수행한다. 또한 데이터의 사용빈도, 중요도에 따라 로그의 라이프사이클을 관리하여 효과적인 디스크 관리를 지원
 FluentD: 수집 및 정제를 위한 모듈로 Kubernetes환경에 DaemonSet으로 구성
 Kibana: 분석을 위한 모듈로 ElasticSearch에 저장된 데이터를 Visualize하는 대시보드

### MSA 분산 DB 환경에서 데이터 조회방안:
 MS 간 독립 DB사용: 각 MSA 자체 데이터를 소유하고 비즈니스를 서비스 내에서 처리할 수 있도록 데이터베이스를 분할하는 것은 어렵지만 고객이 가장 선호하는 패턴. 비즈니스의 대부분을 수정하여 서비스를 재 분류하는 작업부터 시작되어야 한다. 각 서비스가 독립적인 스키마를 갖도록 설계할 경우 서비스간 결합도는 현저히 낮아져 각 서비스가 추구하는 목표에 맞게 서비스를 설계할 수 있다. 그 목표가 성능일 수도, 잦은 배포의 도립성일 수도, 비즈니스 요구사항일 수도 있으며, 독립된 데이터를 갖는 것은 이 목표를 달성하기 위한 충분조건이라 할 수 있다. 다만 스키마의 분리가 쉽지 않기 때문에 모든 서비스를 한번에 전환하는 것보다는 순서를 정하고 분리해 나가는 것이 좋다.
 
 데이터 공유 방식: 완전한 분리가 불가능 하다면, 차선으로 서비스당 2개 이상의 데이터베이스에 접근하는 방법을 선택할 수 있다. 특히 서로 다른 서비스가 독립적인 DB를 갖고, 그 서비스간 데이터 조회를 고려해야 할 경우 테이블에 직접 접근하기 보다는 View를 사용하여 결합도를 낮출 수 있다. View를 사용함으로써 서비스에 표시되는 데이터를 제한하여 액세스해서는 안 되는 정보를 은닉할 수 있다.

 공통 MS 활용: 각 서비스가 명확히 자신의 데이터만을 관리하고 서비스할 수 있다면 가장 좋은 설계라고 했다. 현실적으로 굉장히 어려운 방식이지만, 이를 구현하기 위해 또 하나의 공통 서비스를 생성하고 Shared Data를 관리하는 방식을 고려해 볼 수 있다. 즉 개별적으로 사용하는 데이터는 각 서비스의 DB에 저장하고 공통으로 사용하는 데이터 또는 상호 공유되어야 하는 데이터를 공통서비스 내 공통 DB에 저장한다. 공통서비스는 Front서비스에게 공통 데이터를 직접 액세스 할 수 있도록 앤드포인트를 제공하고, MS간에는 공통 데이터 또는 공유 데이터를 조회할 수 있는 API를 제공. 직접 DB에 액세스 하지 않고 API를 호출하여 결과를 전달 받는 방식으로 구현 

 ReadOnly DB활용: 타 MS의 데이터를 CRUD하는 경우 조회는 ReadOnly DB를 이용하는 방식이다. DB로 복제되며 고객 서비스를 조회할 경우 ReadOnlyDB를 통해 접근할 수 있다. 이때 복제를 구현할 수 있는 방안들은 공통적으로 타이밍 이슈가 발생할 수 있다는 점을 염두해 두고 아키텍처를 설계해야 하며, 업데이트 된 시점을 응용관점에서 관리해 주는 것도 좋은 방법이 될 수 있다. 복제 방법은 DB에서 지원하는 Replication방식을 사용할 수도 있지만 이기종 DB간 지원, Schema변경에 대한 대응을 위한 CDC도구를 사용하는 것이 안정적이다.

### MSA 분산 트랜잭션 관리:
 단일 DB환경에서는 데이터의 안전성과 일관성을 보장하는 데이터베이스에 의존하여 개발과 성능 보장에 포커싱을 춰서 접근할 수 있다. 그러나 데이터베이스 간에 데이터를 분할할 경우 데이터베이스 트랜잭션을 사용하여 상태 변화를 ACID원칙에 따라 보장할 수 없어 그 이점이 사라진다. 이 ACID 속성 중 트랜잭션 경계를 나눌 때 가장 먼저 부딪히는 문제가 원자성이다.
 
* 2Phse Commit:
 2PC는 분산 시스템에서 트랜잭션을 변경할 수 있는 기능을 제공하는 방식이다. 2PC는 투표 단계와 커밋 단계라는 두 단계로 나뉜다. 

 투표 단계: Coordinator가 모든 대상 서비스에 직접 연결하여 상태 변경이 가능한지 확인 요청한다. 이때 각 서비스가 변경 가능 여부에 대해 투표한 즉시 변경사항이 적용되지 않는다는 점을 기억하자. 투표에 동의한 서비스의 변경이 나중에 이루어질 수 있도록 하기 위해 반영 결과에 대해 lock을 걸어 둔다. 만약 투표에 동의하지 않았을 경우 다른 서비스에 롤백 메시지를 보내야한다. 모든 서비스가 투표에 동의하면 Commit 단계로 이동한다. 변경사항이 실제로 적용되고 관련 Lock이 해제된다.

 Commit단계: 모든 서비스에 정확히 동시에 적용된다고 보장할 수 없다. Coordinator는 모든 서비스에게 커밋 요청을 보내야 하며 해당 메세지는 다른 시간에 도착하여 처리될 수 있다. 이는 타이밍 이슈로 한 서비스에 대한 변경 사항을 볼 수 있지만 다른 서비스에 대한 변경 사항은 아직 반영되지 않을 수 있다. 
2PC는 서비스가 증가할 수록 시스템의 대기 시간이 길어지며, 이는 응답시간의 증가를 초래한다. 특히 Lock을 잡아야하는 Row의 범위가 크거나 트랜잭션 기간이 긴 경우 시스템에 엄청난 대기시간을 발생시킨다. 이러한 이유로 2PC는 일반적으로 수명이 매우 짧은 작업에만 사용한다.

 결론: MS전체에서 상태 변경을 조정하기 위해 2PC와 같은 분산 트랜잭션을 사용하지 않는게 좋다. 2PC는 결국 Coordinator를 기반으로 강력한 결합을 유도하고 데이터에 직접적인 Lock을 잡고 처리하기 때문에 서비스간 영향도와 궁극적으로 성능에 지대한 영향을 줄 수 있다.

* Saga Pattern:
 트랜재션의 관리 주체가 DB서버 자신들이 아닌 애플리케이션에 있으며. 애플리케이션이 분산 되었을 때 각 애플리케이션 하위에 존재하는 DB는 자신의 트랜잭션만 처리하는 구조.

 Choreography-Based Saga: 자신이 보유한 서비스 내 DB만의 트랜잭션을 관리하며 트랜잭션이 종료되면 완료 이벤트를 발생. 이어 수행해야 할 트랜잭션이 있다면 해당 애플리케이션으로 완료 이벤트를 발생하고, 해당 이벤트를 받은 애플리케이션에서 계속 트랜잭션을 이어 수행. 마지막에 도달하면 메인 애플리케이션에 그 결과를 전달하여 최종적으로 DB에 영속하는 방법. 이벤트 발행과 구독을 위해 RabbitMQ, Kafka와 같은 메시지 큐 미들웨어를 이용하여 비동기 방식 혹은 분산 처리 형태로 전달할 수 있다. Rollback의 경우 각 애플리케이션에 트랜잭션을 관리하는 로직을 구현하여 중간에 트랜잭션이 실패하면 해당 트랜잭션 취소 처리를 실패한 애플리케이션에서 보상 Event를 발행하여 Rollback처리를 실행

 Orchestration-Based Saga: 트랜잭션 처리를 위한 인스턴스가 별도로 존재하며 이를 Manager라 부른다. 중계적인 역할을 하지만 클라이언트에서의 요청은 한 API에서 한정적이기 때문에 이 인스턴스는 클라이언트의 요청을 받을 애플리케이션과 서비스 인스턴스로도 움직일 수 있다. 트랜잭션을 수행하는 모든 애플리케이션은 Saga 인스턴스 매니저에 의하여 점진적으로 트랜잭션을 수행하여 결과를 Manager에게 전달하는 형태이다. 비즈니스 로직상 마지막 트랜잭션이 끝나면 Saga인스턴스는 전체 트랜잭션이 종료한 뒤 인스턴스는 소멸된다. 만약 중간에 실패하게 되면, Manager가 보상 트랜잭션을 실행하여 일관성을 유지하도록 한다. 모든 관리를 중앙의 매니저가 알아서 해주기 때문에 MSA에서도 트랜잭션을 중앙에서 해주는 구조가 된다. 가장 안정적이고 관리가 편하며 모놀리틱한 형태를 그대로 구현해줄 수 있다는 장점이 있다.

Kubernetes DaemonSet:
클러스터 전체에서 포드를 띄울 때 사용하는 컨트롤러. 데몬셋은 디플로이먼트와 유사하게 파드를 생성하고 관리한다. 디플로이먼트는 롤링 업데이트, 배포 일시 중지 등 배포 작업을 세분화한다면, 데몬셋은 특정 노드 또는 모든 노드에 실행되어야 할 특정 파드를 관리하는 것
데몬셋을 이용해서 포드를 실해하면 해당 포드는 클러스터 전체 노드에 떠 있게 된다. 다시 말해서 클러스터 내에 새롭게 노드가 추가되었을 때 자동으로 그 노드에 데몬셋으로 띄운 포드가 실행되게 되는것. 당연히 노드가 클러스터에서 빠지게 되면 그 노드에 있던 포드는 그래로 사라지고 다른 곳으로 옮겨가서 실행되거나 하지는 않는다. 따라서 데몬셋은 보통 로그수집기를 실행하거나 노드를 모니터링 하는 등 클러스터 전체에 항상 실행시켜 두어야 하는 포드를 실행할 때 사용. 테인트와 톨러레이션 옵션을 사용하면 데몬셋을 전체 클러스터의 노드가 아니라 특정 노드들에만 선택해서 실행할 수 있다.(톨러레이션 옵션은 테인트보다 우선순위가 높다)

# Elasticsearch

## 인덱스란:
Key-Value 구조를 가지는 테이블을 뜻함
Key-Value 구조를 가지는 테이블은 HashMap이라는 자료구조와도 연관이 있다. 특히 대용량 데이터에서 빠르게 데이터를 탐색할때에 매우 유용한 자료구조로 알려져 있다.
보통 index라고 말하는 것은 forward index를 의미한다. 어떤한 주어진 Document들로 index를 생성하면 Document가 Key에 해당하고 Document에 존재하는 Words가 Value에 해당

## 역 인덱스:
위에 나온 Forward Index와 달리 Inverted Index는 Word가 Key가 되고, 그 Word가 존재하는 Document들이 Value가 된다. 즉 아래의 예시에서 처럼 Toy라는 Key로 검색해서 Toy라는 단어가 있는 Document를 찾을 수 있다. 

## 엘라스틱 서치:
### 클러스터 구성:
엘라스틱서치의 노드들은 클라이언트와 통신을 위한 http포트, 노드 간의 데이터 교환을 위한 tcp포트 총 2개의 네트워크 통신을 열어두고 있다. 일반적으로 1개의 물리 서버마다 하나의 노드를 실행하는 것을 권장하고 있다. 하나의 물리적인 서버 안에서 여러 개의 노드를 실행하는 것도 가능하다.

### 디스커버리:
노드가 처음 실행 될 때 같은 서버 또는 discovery.seed_hosts: []에 설정된 네트워크 상의 다른 노드들을 찾아 하나의 클러스터로 바인딩 하는 과정을 디스커버리 라고 한다.

### 인덱스와 샤드:
엘라스틱서치에서는 단일 데이터 단위를 도큐먼트라고 하며 이 도큐먼트를 모아놓은 집합을 인덱스라고 합니다. 인덱스라는 단어가 여러 뜻으로 사용되기 때문에 데이터 저장 단위인 인덱스는 인디시즈라고 표현하기도 합니다. 엘라스틱서치에 저장하는 행위는 색인 그리고 도큐먼트의 집합 단위는 인덱스라고 한다.

인덱스는 기본적으로 샤드(shard)라는 단위로 분리되고 각 노드에 분산되어 저장이 된다. 샤드는 루씬의 단일 검색 인스턴스이다. 같은 샤드와 복제본은 동일한 데이터를 담고 있으며 반드시 서로 다른 노드에 저장된다. 만약 노드3가 시스템 다운이나 네트워크 단절등으로 사라지면 이 클러스터는 가지고 있던 샤드들을 유실하게 되는데 하지만 다른 노드들이 노드3이 가지고 있는 샤드들을 가지고 있어 여전히 전체 데이터는 유실없이 사용가능하다. 처음에 클러스터는 먼저 유실된 노드가 복구 되기를 기다린다. 하지만 타임아웃이 지나 유실된 노드가 복구되지 않는다고 판단이 되면 엘라스틱서치는 복제본이 사라져 1개만 남은 샤드들을 복제 한다. 노드가 줄어들어도 복제가 끝나면 샤드들은 복제본을 가진체 유지가 됩니다.

### 마스터 노드와 데이터 노드:
엘라스틱서치 클러스터는 하나 이상의 노드들로 이루어진다. 이 중 하나의 노드는 인덱스의 메타 데이터, 샤드의 위치와 같은 클러스터. 상태정보를 관리하는 마스터 노드의 역할을 수행한다. 클러스터마다 하나의 마스터 노드가 존재하며 마스터 노드의 역할을 수행할 수 있는 노드가 없다면 클러스터는 작동이 정지된다. 기본적으로는 모든 노드가 마스터 노드로 선출 될 수 있는 노드이다. 만약에 현재 마스터 역할을 수행하고 있는 노드가 네트워크상에서 끊어지거나 다운되면 다른 마스터 후보 노드 중 하나가 마스터 노드로 선출이 되어 마스터 노드의 역할을 대신 수행하게 된다. 마스터 노드 후보들은 처음부터 마스터 노드의 정보들을 공유하고 있기 때문에 즉시 마스터 역할의 수행이 가능하다. 클러스터가 커져서 노드와 샤드들의 개수가 많아지게 되면 모든 노드들이 마스터 노드의 정보를 계속 공유하는 것은 부담이 될 수 있다. 이때는 마스터 노드의 역할을 수행 할 후보 노드들만 따로 설정해서 유지하는 것이 전체 클러스터 성능에 도움이 될 수 있다. 데이터노드는 실제로 색인된 데이터를 저장하고 있는 노드이다. 클러스터에서 마스터 노드와 데이터 노드를 분리하여 설정 할 때 마스터 후보 노드들은 node.data: false로 설정하여 마스터 노드 역할만 하고 데이터는 저장하지 않도록 할 수 있다. 이렇게 하면 마스터 노드는 데이터는 저장하지 않고 클러스터 관리만 하게 되고, 데이터. 노드는 클러스터 관리 작업으로 부터 자유롭게 되어 데이터 처리에만 집중할 수 있다.

마스터 후보 노드를 하나만 놓게 되면 그 마스터 노드가 유실되었을 때 클러스터 전체가 작동을 정지 할 위험이 있다. 그래서 최소한의 백업용 마스터 노드를 설정하게 되는데 이 때 마스터 후보 노드들은 3개 이상의 홀수 개를 놓는 것을 권장하고 있다. 만약에 마스터 후보 노드를 2개 혹은 짝수로 운영하는 경우 네트워크 유실로 인해 마스터 후보 노드인 노드1과 노드2가 분리되면 각자가 서로 다른 클러스터로 구성되어 계속 동작하는 경우가 있을 수 있다. 이 상태에서 각자의 클러스터에 데이터가 추가되거나 변경되고 나면 나중에 네트워크가 복구 되고 하나의 클러스터로 다시 합쳐졌을 때 데이터 정합성에 문제가 생기고 데이터 무결성이 유지될 수 없게 된다. 이런 문제를 Split Brain이라고 한다. Split Brain의 방지를 위해서는 마스터 후보 노드를 3개로 두고 클러스터에 마스터 후보 노드가 최소 2개 이상 존재하고 있을 때에만 클러스터가 동작하고 그렇지 않은 경우 클러스터는 동작을 멈추도록 해야 한다.

### 프라이머리 샤드와 복제본:
인덱스를 생성할 때 별도의 설정을 하지 않으면 7.0부터는 디폴트로 1개의 샤드로 인덱스가 구성되며 6.x이하 버전에서는 5개로 구성이된다. 클러스터에 노드를 추가하게 되면 샤드들이. 각 노드들로 분산되고 디폴트로 1개의 복제본을 생성합니다. 처음생성된 샤드를 프라이머리 샤드(Primary Shard), 복제본은 리플리카(Replica)라고 부른다. 예를 들어 한 인덱스가 5개의 샤드로 구성되어 있고, 클러스터가 4개의 노드로 구성되어 있다고 가정하면 각각 5개의 프라이머리 샤드와 복제본 총 10개의 샤드들이 전체 노드에 골고루 분배되어 저장된다.

### 엘라스틱서치 데이터 처리:
엘라스틱서치는 http 프로토콜로 접근이 가능한 REST API를 지원한다. 자원별로 고유 URL로 접근이 가능하며 http메서드(post,get,delete,put)를 이용해서 자원을 처리한다. -> RESTful한 시스템
MacOS, 리눅스와 같은 유닉스 기반 운영체제에서는 curl명령어로 간편하게 REST API사용이 가능하다.
REST API를 쉽게 사용하기 위해서는 포스트맨 같은 도구를 사용할 수 있다. Kibana에는 엘라스틱서치에서 REST API를 간편하게 실행할 수 있는 Dev Tools도구를 제공한다.

### 벌크 API:
여러 명령을 배치로 수행하기 위해서 _bulk API사용이 가능하다. _bulk API로 index, create, update, delete의 동작이 가능하며 delete를 제외하고는 명령문과 데이터문을 한 줄씩 순서대로 입력해야한다. 벌크 동작은 따로따로 수행하는 것 보다 속도가 훨씬 바르다. 특히 대량의 데이터를 입력 할 때는 반드시 _bulk API를 사용해야 불필요한 오버헤드가 없다. Logstash와 Beats그리고 엘라스틱 웹페이지에서 제공하는 대부분의 언어별 클라이언트에서는 데이터를 입력할 때 _bulk를 사용하도록 개발되어있다.
주의: 엘라스틱서치는 커밋이나 롤백의 트랜잭션 개념이 없다. _bulk작업중 연결이 끊어지거나 시스템이 다운되는 이유로 동작이 중단 된 경우에는 어느 동작까지 실행되었는지 확인이 불가능하다. 이런경우 전체 인덱스를 삭제하고 처음부터 다시 하는 것이 안전하다

### 검색과 쿼리:
상품명이 정확히 “무선 이어폰”인 것만 검색하도록 조건을 엄격하게 하면 표시되는 결과 수가 적어져서 내가 찾는 상품이 나타나지 않을 수 있을 것입니다. 반대로 상품 설명에 “무선”과 “이어폰”이 하나라도 있는. 상품을 모두 검색하도록 하면 “무선 리모컨”,”이어폰 케이스”같은. 상품까지 검색이 되면서 결과가 너무 많아져서 내가 찾는 상품이 묻혀 버릴 수 있다. 품질이 높은 검색 시스템을 구현하기 위해서는 이런 부분을 고민해야 한다.  엘라스틱서치는 사용자가 여러가지 검색 조건들에 대해 목표로 하는 검색. 기능을 구현할 수 있도록 다양한 기능들을 제공한다. 엘라스틱서치는 데이터를. 실제로 검색에 사용되는 검색어인 텀(Term)으로 분석 과정을 거쳐 저장하기 때문에. 검색 시 대소문자 단수나 복수 원형 여부와 상관없이 검색이 가능하다. 이러한 엘라스틱서치의 특징을. 풀 텍스트 검색(Full. Text Search)라고 하며 전문 검색이라고도 한다.

### 정확도:
RDBMS같은 시스템에서는 쿼리 조건에 부합하는 지만 판단하여 결과를 가져올 뿐 각 결과들이 얼마나 정확한지에 대한 판단은 보통 불가능하다. 엘라스틱서치와 같은 풀 텍스트 검색엔진은 검색 결과가 입력된 조건과 얼마나 정확하게. 일치하는 지를 계산하는 알고리즘을 가지고 있어 이 정확도를 기반으로 사용자가 가장 원하는 결과를 먼저 보여줄 수 있다. 이 정확한 정도를 Relevancy라 한다. 검색할 때 사용자는 찾고자 하는 정확한 결과만 보고 싶어한다. 검색 조건에 포함 되더라도 사용자가 찾으려는 결고가와 상관 없는 결과는 보여주지 않는게 좋다. 사용자가 입력한 검색어와 가장 연관성이 있는지를 계산하여 정확도가 가장 높은 결과들 부터 보여준다.
엘라스틱서치의 검색 결과에는 스코어 점수가 표시가 됩니다. 이 점수는 검색된 결과가 얼마나 검색 조건과 일치하는지를 나타내며 점수가 높은 순으로 결과를 보여줍니다.  엘라스틱서치에서는 이 점수를 계산하기 위해 BM25라는 알고리즘을 이용한다. 

### Bool-Should:
Bool쿼리의 should는 검색 점수를 조정하기 위해 사용할 수 있다. 먼저 match 쿼리로 fox를 포함하고 있는 도큐먼트를 검색후 “lazy”가 포함된 결과에 가중치를 줘서 상위로 올리고 싶으면 should안에 lazy를 찾는 검색을 추가한다.

### 정확값 쿼리-ExactValue Query:
풀 텍스트 스코어 점수 기반으로 정확도가 높은 결과부터 가져온다.
문자열 데이터는 KEyword형식으로 저장하여 정확값 검색이 가능하다. 키워드 타입으로 저장된 필드는 스코어를 계산하지 않고 정확값의 일치 여부만을 따진다. 따라서 스코어가 0.0이다.

### 범위 쿼리:
엘라스틱서치는 이 외에도 숫자나 날짜 형식들의 저장이 가능하다. 숫자 날짜 형식은 range쿼리를 이용해서 검색한다.

### 역 인덱스:
일반적으로 오라클이나 MySQL같은 관계형 DB에서는 내용을 보이는 대로 테이블 구조로 저장을 한다. 만약 테이블에서 Text에 Fox가 포함된 행들을 가져온다고 하면 다음과 같이 Text열을 한 줄씩 찾아 내려가면서 Fox가 있으면 가져오고 없으면 넘어가는 식으로 데이터를 가져 올 것이다. 전통적인 RDBMS에서는 위와 같이 like 검색을 사용하기 때문에 데이터가 늘어날수록 검색해야 할 대상이 늘어나 시간도 오래 걸리고 ROW안의 내용을 모두 읽어야 하기 때문에 기본적으로 속도가 느리다.
엘라스틱서치는 데이터를 저장할 때 다음과 같이 역 인덱스라는 구조를 만들어 저장한다. 이 역 인덱스는 책의 맨 뒤에 있는 주요 키워드에 대한 내용이 몇 페이지에 있는지 볼 수 있는 찾아보기 페이지에 비유할 수 있다. 엘라스틱서치에서는 추출된 각 키워드를 텀(term)이라고 부른다. 이렇게 역 인덱스가 있으면 fox를 포함하고 있는 도큐먼트들의 id를 바로 얻어 올수 있다.
엘리스틱 서치는 데이터가 늘어나도 찾아가야 할 행이 늘어나는 것이 아니라 역 인덱스가 가리키는 id의 배열값이 추가되는 것 뿐이기 때문에 큰 속도의 저하 없이 빠른 속도로 검색이 가능하다.  역 인덱스를 데이터가 저장되는 과정에서 만들기 때문에 엘라스틱 서치는 데이터를 입력할 때 저장이 아닌 색인을 한다고 표현, 엘라스틱서치는 루씬의 기능을 대부분 지원하면서 대용량 데이터 처리가 가능 설치와 구성이 용이

### 텍스트 분석:
엘라스틱에 저장되는 도큐먼트는 모든 문자열 필드 별로 역 인덱스를 생성한다. 엘라스틱서치는 문자열 필드가 저장될 때 데이터에서 검색어 토큰을 저장하기 위해 여러 단계의 처리 과정을 거칩니다. 이 전체 과정을 텍스트 분석이라고 하고 이 과정을 처리하는 기능을 애널라이저라고 한다. 엘라스틱의 애널라이저는 0~3개의 캐릭터 필터와 1개의 토크나이저 그리고 0~n개의 토큰 필터로 이루어진다. 텍스트 데이터가 입력되면 가장 먼저 필요에 따라 전체 문장에서 특정 문자를 대치하거나 제거하는데 이 과정을 담당하는 기능이 캐릭터 필터이다. 다음으로는 문장에 속한 단어들을 텀 단위로 하나씩 분리 해 내는 처리 과정을 거치는데 이 과정을 담당하는 기능이 토크나이저이다. 토크나이저는 반드시 1개만 적용이 가능하다. 분리된 텀 들을 하나씩 가공하는 과정을 거치는데 이 과정을 담당하는 기능이 토큰 필터 입니다. 토큰 필터는 0개 부터 여러개를 적용할 수 있다(e.g lowercase 토큰 필터를 이용해서 대문자를 모두 소문자로 바꾼다). 텀 중에는 검색어로서의 가치가 없는 단어들이 있는데 이런 단어를 불용어라고 하고 보통 a, an, are, at, be, but, by, do, for, i, no, the, to등의 단어들은 토큰에서 제외 됩니다. 형태소 분석 과정을 거쳐서 문법상 변형된 단어를 일반적으로 검색에 쓰이는 기본 형태로 변환하여 검색이 가능하게 한다. 필요에 따라서는 동의어를 추가 해 주기도 한다.

### 인덱스 설정과 매핑:
인덱스는 도큐먼트들이 모여 있는 논리적인 데이터의 집합이다. 인덱스는 하나의 노드에만 존재하지 않고 샤드 단위로 구분되어 여러 노드에 걸쳐 저장되어 데이터 무결성의 보장과 검색 성능의 향상을 실현한다. 그 밖에도 데이터의 저장 및 검색 방법에 대한 설정이나 사용자 정의 애널라이저 같은 도구들은 대부분 인덱스 단위로 구분되어 저장이 됩니다. 다시 말해 한 인덱스에서 사용되는 설정이나 도구들은 다른 인덱스에 영향을 미치지 않습니다.

### 집계-Aggregations:
엘라스틱서치는 검색엔진으로 개발되었지만 지금은 로그분석을 비롯해 다양한 목적의 데이터 시스템으로 사용되고 있다. 엘라스틱서치가 이렇게 다양한 용도로 활용이 될 수 있는 이유는 데이터를 단순히 검색만 하는 것이 아니라 여러가지 연산을 할 수 있는 Aggregation기능이 있기 때문이다.  Aggregation에는 크게 Metrics그리고 Bucket 두 종류가 있다. Aggregations구문이나 옵션에 Metrics이거나 Bucket이라고 따로 명시를 하지는 않는다. Aggregation 종류들 중 숫자 또는 날짜 필드의 값을 가지고 계산을 하는 Aggregation들을 Metrics Aggregation이라고 분류하고 범위나 Keyword값 들을 가지고 도큐먼트들을 그룹화 하는 Aggregation들을 Bucket Aggregation이라고 분류한다

# Python
## 스크립트 언어와 컴파일 언어의 차이:
작성한 코드를 컴퓨터가 알아듣기 위해서는 프로그래밍 언어를 기계어(0,1)(CPU인스트럭션)로 번역하는 과정이 필요한데, 그 과정을 언어에 따라 컴파일 혹은 인터프릿이라고 하고, 각각을 실행하는 변환기를 컴파일러, 인터프리터라고 한다. 컴파일을 하는 언어를 컴파일 언어 인터프릿을 하는 언어를 인터프리터 언어 혹은 스크립트 언어라고 한다.

컴파일 언어는 이미 기계어로 번역된 파일을 컴퓨터가 실행하므로 스크립트 언어에 비해 빠르고 소스코드에 문법적 오류가 있으면 컴파일 에러를 발생시켜 디버깅이 수월하다. 하지만 일반적으로 문법적 제약이 많아 작성이 비교적 어렵고, 운영체제마다 사용하는 기계어가 다르기 때문에 운영체제에 따라 작업을 각각 다르게 해줘야 하는 단점이 있다.

스크립트 언어는 컴퓨터가 코드를 실행하는 과정에서 소스 코드를 기계어로 번역하는 과정이 포함되어 있으므로 컴파일 언어에 비해 느리다. 또 문법적 오류가 있든 없든 일단 실행되기 때문에 디버깅이 비교적 어렵다. 하지만 문법 적 제약이 비교적 적어 작성이 비교적 쉽고 운영체제를 신경 쓸 필요 없이 한 번만 작성해놓으면 된다는 장점이 있다.

컴파일 방식의 언어에 의해 작성되는 응용 프로그램은 컴파일러에 의해 기계어로 번역된 채로 실행되기 때문에 수정이 빈번하게 발생할 경우에는 수정 후 다시 컴파일을 해야하는 불편함이 존재한다. 참고로 덩치가 큰 프로그램은 컴파일 시간이 꽤 길다. 즉 간단한 수정에도 오랜 기간의 컴파일 시간이 요구되는 단점이 있다.  수정이 빈번하게 발생하는 경우에는 소스 코드를 한줄 한줄 읽어 바로바로 실행하는 인터프리터 방식이 상당히 유리하다. 

## 파이썬은 인터프리터 언어인가?
### 컴파일언어: 
정확하게 말하면 컴파일 되는 언어라고 해야 의미가 분명하다. 컴파일언어는 컴파일러에 의해서 구현되는 언어를 말한다. 컴파일러는 컴파일러를 수행하는 프로그램이라는 뜻인데 그럼 컴파일이란 무엇인가? 흔히 컴파일을 C와 같은 언어에서 프로그램 소스코드를 기계어로 번역하는 것을 말하는데 이것은 매우 좁은 의미의 컴파일이며, 일반적으로 컴파일은 하나의 언어 코드를 다른 언어로 변환하는 것을 말한다. 가장 흔히 알려진 컴파일러인 C컴파일러는 C소스코드를 기계어(CPU인스트럭션을 말한다)로 번역하는 일을. 수행하는 프로그램이다. 넓은 의미에서 컴파일러는 보다 다양한 언어에서 찾아볼 수 있다. 예를 들어 TypeScript는 Javascript로 해석되어 실행되는 언어이다. 따라서 TypeScript는 컴파일러를 통해 컴파일되며, 그 결과는 기계어 코드가 아닌 Javascript코드가 된다. 고전적 의미에서 컴파일 언어는 주로 실행 시간 이전에 기계어 코드로 번역되는 언어라고들 정의한다. 하지만 당장 위 TypeScript만 보아도 이러한 정의로는 커버할 수 없다는 것을 알 수 있다.

전통적인 의미의 인터프리터 언어는 실행전에 기계어로의 컴파일 과정을 거치지 않으며 소스코드가 해석기에 의해 직접 해석되어 실행되도록 구현된 언어를 말한다. 소스코드가 의도하는 작업의 실질적인 수행은 이를 해석한 인터프리터에 의해서 수행된다. 따라서 인터프리터는 이 경우에 일종의 가상머신이나 실행환경 혹은 에뮬레이터 같은 것으로 이해할 수 있다. 하지만 역시나 이 정의를 따르면 Java는 컴파일 언어가 아닌 인터프리터 언어가 되고 만다.
진짜 문제는 컴파일 언어냐 인터프리터 언어냐 하는 것이 언어 자체를 분류하거나 구분짓는 특성이 아니라는 것이다. 이것은 언어 구현의 문제이다. 초창기 프로그래밍 언어들의 역사에서 인터프리터 방식은 언어를 규정하는 특징이라기 보다는 목적과 용도에 따라 실제 작동에 대한 구현의 방식을 정한 것일 뿐이다. 고전적인 의미의 인터프리터는 한줄씩 명령어를 입력하여 즉각적인 동시에 단계적으로 명령을 실행해 나가는 환경이 필요하여 그러한 방식으로 개발된다. 흔히 명령 프롬프트로 대표되는 cmd.exe나 bash와 같은 쉘이 인터프리터 언어의 대표적인 형태이다. 파이썬은 인터랙티브 쉘의 형태로 실행되는 모드에서 이처럼 한 줄씩 코드를 입력해서 실행해볼 수 있기 때문에 흔히 인터프리터 언어로 분류되고 있다.

어떤 언어가 컴파일러 방식으로 구현되어 있든 인터프리터 방식으로 구현되어 있든 간에 CPU가 실행할 수 있는 명령은 모두 네이티브 코드인 CPU인스트럭션 뿐이며 개개의 CPU인스트럭션은 아주 간단한 명령들이다. 따라서 에셈플리나 기계어로된 코드가 아닌 이상 대부분의 언어는 번역이 필요하고 소스코드로부터 출발해서 기계어 코드가 실행되는 과정에서 가장 비용이 많이 드는 구간은 소스코드를 해석하는 과정이다. 따라서 어떤 언어가 프로덕션 레벨에서도 고전적 의미의 인터프리터처럼. 매번 소스코드의 매 라인을 해석해서 실행해야 한다면 이 해석작업 때문에 전체프로그램의 퍼포먼스에서 크게 손해를 보게 된다. 이런 문제를 극복하기 위해 파이썬은 소스코드를 바이트 코드로 컴파일한다음 이 바이트코드를 해석기가 돌려주는 방식으로 실행한다. 이 때 말하는 바이트코드는 해석기가 사용하는 명령어세트로 처리된 코드로 가상 머신을 위한 에셈블리 코드 정도로 이해하면 된다. 파이썬은 인터프리터 언어일까 컴파일 언어일까? 인터프리터/컴파일의 구분은 언어의 특성이 아닌 구현의 문제이다.

표준 파이썬 구현체인 CPython의 인터프리터는 소스코드를 바이트코드로 컴파일 한 후 처리한다. 그럼 앞서 말했던 정의를 따르자면 컴파일 언어에 해당한다고 볼 수 있다. 심지어 pypy같은 파이썬 구현체는 JIT를 탑재하고 있기 때문에 실행 시간에 기계어 코드를 직접 생성하여 돌린다. 인터프리터가 존재한다고 해서 이걸 과연 인터프리터 언어라고 부를 수 있을까 컴파일 방식이냐 인터프리터 방식이냐를 구현체로 구분해야 하는 극명한 예를 살펴보자.
Cython이라는 프로젝트가 있다. 파이썬 소스코드를 C언어로 컴파일하는 프로젝트이다. 여기에는 cdef같은 추가적인 문법이 들어가기도 하는데, 어쨌든 파이썬 소스코드를 C언어로 바꾼다는 것이다. 그렇다면 우리는 이를 통해 온전한 C언어 소스를 얻을 수 있고 그 이후의 과정에서 C컴파일러를 사용한다면 기계어로 된 실행파일을 생성할 수 있다는 이야기다. 누군가는 Cython은 cdef같은 추가적인 문법을 사용하여 C함수를 작성할 수 있는 물건이며, Cython전용 코드는 파이썬으로 실행할 수 없기 때문에 Python과 같은 언어로 볼 수 없다는 주장을 할 수 있다. 그렇다면 Nuitka는 순수 파이썬으로 만들어진 파이썬 컴파일러로 순수한 파이썬 코드를 C코드로 완전하게 컴파일 할 수 있으며 C컴파일러를 사용해서 실행 파일로 만들 수 있기까지 하다. 이 외에도 목적 언어가 바이트코드나 기계어가 아닌 범용언어가 되는 컴파일러들은 제법 많이 존재한다.
소스코드와 기계어 코드의 중간에 해당하는 바이트 코드를 사용하는 언어로는 대표적으로 Java가 있다. Java는 소스코드를 바이트코드로 컴파일한 후 Java VM이라고 하는 실행환경에서 돌아간다. 흔히 하나의 소스코드를 수정 없이 모든 플랫폼에서 실행할 수 있다는 것을 장점으로 내세운다. 이 것만 봐서는 Java역시 인터프리터 언어가 아니냐고 말할 수도 있을 것이다. 틀린 말은 아니다. Java는 바이트코드로 컴파일되지만 VM은 인터프리터처럼 돌아갈 수 있다. 심지어 최근의 Java VM구현은 JIT컴파일러를 포함하여 일부 구간에서는 최적화를 수행하여 기계어 코드를 생성하여 바로 실행할 수 있기까지 하다. 자바와 자바스크립트는 다른 언어이지만 자바 스크립트 역시 바이트코드로 컴파일되어 자바스크립트 VM에서 실행하는 방식으로 돌아간다. 그 외에도 많은 언어들이 유연함과 성능을 모두 잡기 위해서 바이트코드를 사용하는 형태로 구현되고 있다. 뿐만 아니라 C언어를 자바스크립트로 컴파일하여 자바스크립트 VM에서 실행할 수 있게 하는 프로젝트도 있다.

앞에서 컴파일 방식 언어에 대한 설명을 하면서 실행시간 전에 컴파일을 한다고 했는데 이러한 방식을 AOT(Ahead of Time)컴파일러라고 한다. 컴파일 언어하면 딱 떠오르는 C나 하스켈의 컴파일러들이 여기에 해당한다. 앞서 언급한 JIT컴파일러는 프로그램 실행 중에 프로그램 실행 흐름을 관찰하여 더욱 최적화된 기계어 코드를 생성해서 프로그램 실행을 가속화하는 방식이다. Java VM에도 탑재가 되어 있으며 파이썬으로 만든 파이썬 구현체인 pypy나 Julia와 같은 언어가 JIT컴파일러를 사용한다. 이런 언어들은 특정한 유형의 문제에 대해서 언어 중에서 성능 최고라는 C보다도 더 빠른 실행 속도를 보이기도 한다.

### 결론 
어떤 언어 자체를 인터프리터 언어/컴파일 언어로 구분하는 것은 잘못된 접근이다. 이 두 방식은 언어 구현에 있어서의 접근법이며, 기존에 존재하는 언어라도 새 구현체를 만들어서 그 작동 방식을 바꿀 수 있다. 최근 개발되는 언어들과 혹은 아주 오래되었지만 계속해서 발전해나가는 언어들은 표준. 구현에서 두 가지 방식에서 장점만을 취하거나 혹은 필요에 따라서는 두 가지 방식 모두를 포함하는 형태로 개발되고 있다. 그래서 일단 표준 파이썬 구현체는 인터프리터 안에 컴파일러를 내장하고 있다.

## 메모리 관리의 이유:
메모리 사용을 마쳤을 때 비우지 않을 경우 메모리 누수가 발생할 수 있고 장기적인 관저에서 심각한 문제가 발생할 수 있다.  
존재하지 않는 메모리에 접근하려고 하면 프로그램이 중단되거나 메모리 데이터 값이 손상될 수 있다. 

## Reference Counting: 주요 GC mechanism은 레퍼런스 카운팅 방식이다.
Python에서 객체를 때마다 기본 C객체에서는 Python유형(list,dict또는 function)과 레퍼런스 카운트가 생성된다. 매우 기본적으로 객체의 레퍼런스 카운트는 객체가 참조될 때마다 증가하고 객체의 참조가 해제될 때 감소한다. 객체의 레퍼런스 카운트가 0이 되면 객체의 메모리 할당이 해제된다. 참조 횟수를 증가시키는 방법은 변수에 객체를 할당 하거나 list에 추가하거나 class instance에서 속성으로 추가하는 등의 데이터구조에 객체 추가하거나 객체를 함수의 인수로 전달할 때 다.

## Generational GC: 
Python은 메모리 관리를 위한 레퍼런스 카운팅 외에도 Generational GC이라는 방법을 사용한다. 레퍼런스 카운팅이 주로 사용되는 방법이고 보조로 GC를 사용한다는 것이다. 왜 가비지 컬렉션이 필요한가? 전에 객체를 배열이나 객체에 추가하면 참조 횟수가 증가하는 것을 확인 할 수 있다. 그러나 객체가 순환 참조(순환 참조는 객체가 자기 자신을 가르키는 것을 말한다)하면 어떻게 작동 될까? a=[], a.append(a), del a a의 참조 횟수는 1이지만 이 객체는 더 이상 접근할 수 없으며 레퍼런스 카운팅 방식으로는 메모리에서 해제될 수 없다. a = Func_pr(), b = Funnc_pr(), a.x = b, b.x = a, del a, del b 마지막 상태에서 0x01.x와 0x02.x가 서로를 참조하고 있기 때문에 레퍼런스 카운트는 둘다 1이지만 0에 도달할 수 없는 쓰레기가 된다. 이러한 유형의 문제를 레퍼런스 사이클이라고 하며 레퍼런스 카운팅으로 해결할 수 없다. 

## Generational GC와 이해해야 할 두 가지 주요 개념 
첫 번째는 Generation개념이다. 가비지 컬렉터는 메모리의 모든 객체를 추적한다. 새로운 객체는 1세대 GC에서 life를 시작한다. 파이썬이 세대에서 가비지 수집 프로세스를 실행하고 객체가 살아남으면 두 번째 이전 세대로 올라간다. 파이썬 가비지 수집기는 총 3세대이며, 객체는 현재 세대의 가비지 수집 프로세스에서 살아남을 때마다 이전 세대로 이동한다. 
두 번째 핵심 개념은 Threshold(임계)값이다. 각 세대마다 가비지 컬렉터 모듈에는 임계값 개수의 객체가 있다. 객체 수가 해당 임계값을 초과하면 가비지 콜렉션이 콜렉션 프로세스를 추적한다. 해당 프로세스에서 살아남은 객체는 이전 세대로 옮겨진다. 가비지 컬렉터는 내부적으로 세대와 임계값으로 가비지 컬렉션 주기와 객체를 관리한다. 세대는 0~2세대로 구분되고 최근 생성된 객체는 0세대에 들어가고 오래된 객체일수록2세대로 이동한다. 당연히 한 객체는 단 하나의 세대에만 속한다. 가비지 컬렉터는 0세대일수록 더 자주 가비지 컬렉션을 하도록 설계되어있는데 Generational Hypothesis에 근거한다. 이 가설은 대부분 어린 객체가 오래된 객체보다 해제될 가능성이 훨씬 높다는 가설이다. 레퍼런스카운팅 메커니즘과 달리 파이썬 프로그램에서 세대 가비지 컬렉터의 동작을 변경할 수 있다. 여기에는 코드에서 카비지 콜렉션 프로세스를 트리거하기 위한 임계값 변경, 가비지 컬렉션 프로세스를 수동으로 트리거 하거나 가비지 컬렉션 프로세스를 모두 비활성화하는것이 포함된다.
왜 GC는 성능에 영향을 주나? 가비지 컬렉션을 수행하려면 응용프로그램을 완전히 중지해야 한다. 그러므로 객체가 많을수록 모든 가비지를 수집하는데 시간이 오래 걸린다는 것도 분명하다. 가비지 컬렉션 주기가 짧다면 응용프로그램이 중지되는 상황이 증가하고 반대로 주기가 길어진다면 메모리 공간에 가비지가 많이 쌓일 것이다. 시행 착오를 거치며 응용프로그램의 성능을 끌어 올려야 한다. 
GC 모듈 사용하여 가비지 컬렉션 통계를 확인하거나 가비지 컬렉터의 동작을 변경할 수 있다. get_threshold()를 사용하여 가비지 컬렉터의 구성된 임계값을 확인할 수 있다. get_count() 메소드를 사용하여 각 세대의 객체 수를 확인할 수 있다. 파이썬은 프로그래을 시작하기 전에 기본적으로 많은 객체를 생성한다. gc.collect()메소드를 사용하여 수동 가비지 콜렉션 프로세스를 추적할 수 있다. set_threshold()메소드를 사용하여 가비지 컬렉션 트리거 임계값을 변경할 수 있다. 임계 값을 증가시키면 가비지 컬렉션이 실행되는 빈도가 줄어든다. 죽은 객체를 오래 유지하는 비용으로 프로그램에서 계산 비용이 줄어든다.

수동가비지 컬렉션은 수행하는 방법은 두가지가 있다. Time-Based:가비지 컬렉터를 고정된 시간 간격마다 호출하는 것이다. Event-Based: 이벤트 발생 시 가비지 컬렉터를 호출한다. 예를 들어 사용자가 응용프로그램을 종료하거나 응용프로그램이 중단 상태일 때 호출하는 것이다.
